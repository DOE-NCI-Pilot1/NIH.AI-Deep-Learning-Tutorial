{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From in-vitro Panels to Virtual Screening Models \n",
    "\n",
    "Prepared to accompany talk for NIH.AI workshop on 23-Oct 2019. This notebook is an example of a method only and is not meant to demonstrate effective modeling techniques for cancer dose-response models. \n",
    "\n",
    "Please contact Austin Clyde, aclyde@anl.gov, for questions regarding the content in this notebook. \n",
    "\n",
    "## Setup environment. \n",
    "I recommend using Conda to manage the python environment. Some modules used later on will require Conda to avoid custom C builds. For the neural network section, running this code on a GPU is highly recommended to keep runtimes in a reasonable number, if you do not have a GPU available, please reduce the data size parameter in the sections below. \n",
    "\n",
    "```shell\n",
    "cd <this directory>\n",
    "conda create ...\n",
    "conda activate \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class Avg:\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def __call__(self, i):\n",
    "        self.sum += i\n",
    "        self.count += 1\n",
    "    \n",
    "    def avg(self):\n",
    "        return self.sum / self.count\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "As mentioned in the presentation, to keep this code applicable, I tried to keep this notebook as general as possible for panel and screening problems. We will define our panel as having $N$ observations consisting of a tumor and drug, $N_t$ tumor cells which we draw from, and $N_d$ drugs.\n",
    "\n",
    "$$\\hat{R}=\\hat{f}_\\theta (\\mathcal{T}, \\mathcal{D})$$\n",
    "we can think of this as neededing three data tables, $R$, $T$, and $D$.\n",
    "\n",
    "- $R$ is $N$ by $3$ and is our response variable, most commonly referred to as $y_\\text{obsesrved}$. \n",
    "- $T$ is $N_t$ by $\\mid{F_t}\\mid$ and is our characterization of the tumor cells. $F_t$ can be anything from encoding the name of the cell to the type, even RNA-seq quantification.\n",
    "- $D$ is $N_d$ by $\\mid{F_d}\\mid$ and is our characterization of the drug cells. $F_d$ can be anything from the name of the drug to the type of drug to various properties.\n",
    "\n",
    "Notice so far that in our set of this problem, we have kept it general enough that you could swap out these datasets with any two variables panel your lab may use. For binding affinity predictions, we can swap T, tumor cells, to P for protein mutants or protein sequences.\n",
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_R = pd.read_csv(\"/Users/austin/combined_single_response_agg\", sep='\\t', engine='c', low_memory=False)\n",
    "unique_cells, unique_drugs = list(set(df_R.CELL)), list(set(df_R.DRUG))\n",
    "\n",
    "df_T = pd.DataFrame({'CELL' : unique_cells, 'FEATURE' : unique_cells})# get feature frames just by the name of the cell\n",
    "df_D = pd.DataFrame({'DRUG' : unique_drugs, 'FEATURE' : unique_drugs})# get feature frames just by the name of the drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It just so turns out that our $R$ data frame has lots of extra columns we will not be using. We will remove those for the sake of generality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL</th>\n",
       "      <th>DRUG</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CCLE.1321N1</td>\n",
       "      <td>CCLE.1</td>\n",
       "      <td>0.8330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CCLE.1321N1</td>\n",
       "      <td>CCLE.10</td>\n",
       "      <td>0.7909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CCLE.1321N1</td>\n",
       "      <td>CCLE.11</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CCLE.1321N1</td>\n",
       "      <td>CCLE.12</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CCLE.1321N1</td>\n",
       "      <td>CCLE.14</td>\n",
       "      <td>0.5688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CELL     DRUG     AUC\n",
       "0  CCLE.1321N1   CCLE.1  0.8330\n",
       "1  CCLE.1321N1  CCLE.10  0.7909\n",
       "2  CCLE.1321N1  CCLE.11  0.5255\n",
       "3  CCLE.1321N1  CCLE.12  0.8532\n",
       "4  CCLE.1321N1  CCLE.14  0.5688"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_R = df_R[['CELL', 'DRUG', 'AUC']]\n",
    "df_R.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice our featurization method initially is just the name of the cell or name of the drug (this is obviously not the best way!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL</th>\n",
       "      <th>FEATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CCLE.MFE280</td>\n",
       "      <td>CCLE.MFE280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CTRP.KASUMI-1</td>\n",
       "      <td>CTRP.KASUMI-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gCSI.SU-86-86</td>\n",
       "      <td>gCSI.SU-86-86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CTRP.BT139</td>\n",
       "      <td>CTRP.BT139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CTRP.HEC-251</td>\n",
       "      <td>CTRP.HEC-251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CELL        FEATURE\n",
       "0    CCLE.MFE280    CCLE.MFE280\n",
       "1  CTRP.KASUMI-1  CTRP.KASUMI-1\n",
       "2  gCSI.SU-86-86  gCSI.SU-86-86\n",
       "3     CTRP.BT139     CTRP.BT139\n",
       "4   CTRP.HEC-251   CTRP.HEC-251"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRUG</th>\n",
       "      <th>FEATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NSC.641536</td>\n",
       "      <td>NSC.641536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NSC.689732</td>\n",
       "      <td>NSC.689732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NSC.153365</td>\n",
       "      <td>NSC.153365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NSC.626117</td>\n",
       "      <td>NSC.626117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NSC.711897</td>\n",
       "      <td>NSC.711897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DRUG     FEATURE\n",
       "0  NSC.641536  NSC.641536\n",
       "1  NSC.689732  NSC.689732\n",
       "2  NSC.153365  NSC.153365\n",
       "3  NSC.626117  NSC.626117\n",
       "4  NSC.711897  NSC.711897"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_D.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*a good habit is to look at the distribution of the target you want to predict. The skewness or normality of this distribution will significantly influence our choices in models later on*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_R.AUC, bins=100)\n",
    "plt.yscale('log')\n",
    "plt.title(\"Log Histogram of Target Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note that our response distribution is very skewed to the right. In fact, if we bin the distribution at 0.5, only 2% of our data would be labeled as a positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First attempt at Machine Learning\n",
    "Okay, great, we have our response data frame, and have the most basic characterization of the tumor and drug features. Now comes the somewhat tricky part of the data preparation. We need to perform a join over the data:\n",
    "\n",
    "tmp = JOIN($R$, $T$, on='CELL')\n",
    "\n",
    "JOIN(tmp, $D$, on='CELL)\n",
    "\n",
    "but in pandas, it is confusingly called merge... \n",
    "\n",
    "**This may require a lot of memory and take awhile. I recommend just for development and playing around with this notebook, reducing the number of samples you are using in $R$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>FEATURE_x</th>\n",
       "      <th>FEATURE_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>CCLE.1321N1</td>\n",
       "      <td>CCLE.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>CCLE.22RV1</td>\n",
       "      <td>CCLE.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>CCLE.42MGBA</td>\n",
       "      <td>CCLE.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>CCLE.5637</td>\n",
       "      <td>CCLE.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>CCLE.639V</td>\n",
       "      <td>CCLE.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUC    FEATURE_x FEATURE_y\n",
       "0  0.8330  CCLE.1321N1    CCLE.1\n",
       "1  0.7153   CCLE.22RV1    CCLE.1\n",
       "2  0.8126  CCLE.42MGBA    CCLE.1\n",
       "3  0.7833    CCLE.5637    CCLE.1\n",
       "4  0.7675    CCLE.639V    CCLE.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REDUCE DATA BY RUNNING THIS CELL\n",
    "nsamples_to_use = 1000\n",
    "df_R = df_R.iloc[:nsamples_to_use]\n",
    "\n",
    "tmp = pd.merge(left=df_R, right=df_T, on='CELL', how='inner')\n",
    "df = pd.merge(left=tmp, right=df_D, on='DRUG', how='inner')\n",
    "df = df.drop(['CELL', 'DRUG'], axis=1) # remove the columns we used for merging feature frames\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have both features merely being the name of the corresponding cell line or drug assigned by the respective cancer study. We call this type of labeling categorical data, and it needs to be encoded for use in machine learning algorithms (no math equation can understand \"CCLE.14\"). \n",
    "\n",
    "One example of this is an ordinal encoder. We will take each drug and provide it a number\n",
    "- CCLE.1 -> 0\n",
    "- CCLE.2 -> 1\n",
    "- NSC.2312 -> 2\n",
    "- ...\n",
    "\n",
    "and similar for drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>FEATURE_x</th>\n",
       "      <th>FEATURE_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC  FEATURE_x  FEATURE_y\n",
       "544  0.8276       29.0       15.0\n",
       "499  0.8446       27.0       14.0\n",
       "995  0.8230       34.0       11.0\n",
       "636  0.5810       35.0       17.0\n",
       "935  0.8211        8.0        8.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oridinal_encoder = sklearn.preprocessing.OrdinalEncoder()\n",
    "df.iloc[:,1:] = oridinal_encoder.fit_transform(df.iloc[:,1:])\n",
    "df.sample(frac=1).head() #df.sample(frac=1) just shuffles it so you can see different FEATURE_x and FEATURE_y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = np.array(df.iloc[:,1:]), np.array(df.iloc[:,0], dtype=np.float32)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold  0 : -0.06151623805760687\n",
      "Cross fold  1 : -0.06260157493806284\n",
      "Cross fold  2 : -0.08526507335845858\n",
      "Cross fold  3 : 0.030034655687436684\n",
      "Cross fold  4 : 0.10972354098322945\n",
      "Cross fold  0 : -0.7048934811029846\n",
      "Cross fold  1 : -1.0182151689274321\n",
      "Cross fold  2 : -1.5111994908687436\n",
      "Cross fold  3 : -0.29620104423368\n",
      "Cross fold  4 : -0.452865742271803\n",
      "Linear Model Avg:  -0.013924937936692427\n",
      "RF Model Avg:  -0.7966749854809286\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model and RandomForest Regrerssor\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "cv = sklearn.model_selection.KFold(5, random_state=42)\n",
    "lin_avg_r2 = Avg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    lr = sklearn.linear_model.LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    test_r2 = lr.score(X_test, y_test)\n",
    "    print(\"Cross fold \", i, \":\", test_r2)\n",
    "    lin_avg_r2(test_r2)\n",
    "    \n",
    "cv = sklearn.model_selection.KFold(5, random_state=42)\n",
    "rf_avg_r2 = Avg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    lr = sklearn.ensemble.RandomForestRegressor(n_estimators=10, n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    test_r2 = lr.score(X_test, y_test)\n",
    "    print(\"Cross fold \", i, \":\", test_r2)\n",
    "    rf_avg_r2(test_r2)\n",
    "    \n",
    "print(\"Linear Model Avg: \", lin_avg_r2.avg())\n",
    "print(\"RF Model Avg: \", rf_avg_r2.avg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this featurization method is suboptimal. Let us try considering this as a regression case, remember we can turn it into one by binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold  0 : 0.9054726368159204\n",
      "Cross fold  1 : 0.905\n",
      "Cross fold  2 : 0.905\n",
      "Cross fold  3 : 0.905\n",
      "Cross fold  4 : 0.9095477386934674\n",
      "Cross fold  0 : 0.945273631840796\n",
      "Cross fold  1 : 0.945\n",
      "Cross fold  2 : 0.92\n",
      "Cross fold  3 : 0.945\n",
      "Cross fold  4 : 0.9346733668341709\n",
      "Linear Model Avg:  0.9060040751018775\n",
      "RF Model Avg:  0.9379893997349933\n"
     ]
    }
   ],
   "source": [
    "CUTOFF = 0.5\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "# StratifiedKFold attempts to keep y values distributed evenly across folds. Useful for classification\n",
    "cv = sklearn.model_selection.StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "lin_avg_acc = Avg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "    \n",
    "    lr = sklearn.linear_model.LogisticRegression(solver='lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "    test_acc = lr.score(X_test, y_test)\n",
    "    print(\"Cross fold \", i, \":\", test_acc)\n",
    "    lin_avg_acc(test_acc)\n",
    "    \n",
    "# StratifiedKFold attempts to keep y values distributed evenly across folds. Useful for classification\n",
    "cv = sklearn.model_selection.StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "rf_avg_acc = Avg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "    \n",
    "    lr = sklearn.ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    test_acc = lr.score(X_test, y_test)\n",
    "    print(\"Cross fold \", i, \":\", test_acc)\n",
    "    rf_avg_acc(test_acc)\n",
    "    \n",
    "print(\"Linear Model Avg: \", lin_avg_acc.avg())\n",
    "print(\"RF Model Avg: \", rf_avg_acc.avg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems impressive, right? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold  0 : 0.9157175398633257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold  1 : 0.9152619589977221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold  2 : 0.9161731207289294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold  3 : 0.9179206566347469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold  4 : 0.9174646602827178\n",
      "Cross fold  0 : 0.8779043280182233\n",
      "Cross fold  1 : 0.875626423690205\n",
      "Cross fold  2 : 0.8783599088838269\n",
      "Cross fold  3 : 0.8732330141358869\n",
      "Cross fold  4 : 0.8736890104879161\n",
      "Linear Model Avg:  0.9165075873014885 BalAcc 0.49891481561656487\n",
      "RF Model Avg:  0.8757625370432118 BalAcc 0.49037743652054255\n"
     ]
    }
   ],
   "source": [
    "CUTOFF = 0.5\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "# StratifiedKFold attempts to keep y values distributed evenly across folds. Useful for classification\n",
    "cv = sklearn.model_selection.StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "lin_avg_acc = Avg()\n",
    "lin_avg_balacc = Avg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "    \n",
    "    lr = sklearn.linear_model.LogisticRegression(solver='lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "    test_acc = lr.score(X_test, y_test)\n",
    "    print(\"Cross fold \", i, \":\", test_acc)\n",
    "    lin_avg_acc(test_acc)\n",
    "    lin_avg_balacc(sklearn.metrics.balanced_accuracy_score(y_test, lr.predict(X_test)))\n",
    "\n",
    "\n",
    "# StratifiedKFold attempts to keep y values distributed evenly across folds. Useful for classification\n",
    "cv = sklearn.model_selection.StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "rf_avg_acc = Avg()\n",
    "rf_avg_balacc = Avg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "    \n",
    "    lr = sklearn.ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    test_acc = lr.score(X_test, y_test)\n",
    "    print(\"Cross fold \", i, \":\", test_acc)\n",
    "    rf_avg_acc(test_acc)\n",
    "    rf_avg_balacc(sklearn.metrics.balanced_accuracy_score(y_test, lr.predict(X_test)))\n",
    "    \n",
    "print(\"Linear Model Avg: \", lin_avg_acc.avg(), \n",
    "      \"BalAcc\", lin_avg_balacc.avg())\n",
    "print(\"RF Model Avg: \", rf_avg_acc.avg(), \n",
    "      \"BalAcc\", rf_avg_balacc.avg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But notice that the accuracy balanced across both the positive and negative classes is only 75%, and the confusion matrix shows the model is mostly just guessing everything does not respond, and it does quite well at that. By noticing this, we can be cautious of understanding when our model is successful and when it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[sklearn.utils.multiclass.unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "#    plt.show()\n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEKCAYAAABHZsElAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5hU5fnG8e+9gCDVLsUOooIKgmh+xq6xJPZo7D222BKDiTUaE2PBxIIao7G3oIkdazTWgGBDJCpKsSAWsCJiWZ7fH++7OKzLsiCzc9i9P9c1FzPnnDnznNlhnnm7IgIzM7Oiqap0AGZmZnVxgjIzs0JygjIzs0JygjIzs0JygjIzs0JygjIzs0JygjJbACSdLumGfH8FSdMktVjArzFR0pYL8pwNeM0jJL2Xr2fJ73GeaZJWWZCxVYqkMZI2rXQczYETlC0U8pfz+5LalWz7uaRHKxhWnSLizYhoHxHVlY7l+5DUCvgLsFW+nqnze678/PELLroFT9I1kv44t+MiondEPNoIITV7TlC2MGkBHPt9T6LEn/25WxZoA4ypdCBFIKllpWNobvyf1BYmg4CBkhara6ekDSSNlPRJ/neDkn2PSjpT0lPAdGCVvO2Pkv6bq6DulrSkpBslfZrPsVLJOS6U9Fbe96ykjeYQx0qSQlJLSf+Xz11zmyFpYj6uStIJksZJmirpFklLlJxnX0lv5H0n1/fGSFpU0p/z8Z9IelLSonnfDrla6uN8zWuUPG+ipIGSXszPGyKpjaSewKv5sI8lPVJ6XbXe15/n+z0kPZbPM0XSkJLjQlKPfL+TpOskfZDjPaXmB4OkA3Ls50n6SNIESdvWc90TJR2f4/9c0pWSlpV0n6TPJP1b0uIlx98q6d0c4+OSeufthwJ7A7+p+SyUnP+3kl4EPs9/01lVrZLulfTnkvP/Q9JV9f2trOGcoGxh8gzwKDCw9o78xT4UuAhYklQ1NVSzt5vsCxwKdADeyNv2yNu7Ad2BYcDVwBLAy8BpJc8fCfTN+24CbpXUpr6AI2JYrt5qDywOPA3cnHcfDewEbAJ0BT4CLsnX0wv4a46ta76m5ep5qfOA/sAGOb7fADNzorkZ+CWwNHAvcLekRUqe+zNgG2BlYG3ggIgYC/TO+xeLiM3ru87sD8CD+TqXAwbP4bjBQCdglXzt+wEHluxfn5QclwLOBa6UpHpe96fAj4CewPbAfcBJ+XqrgGNKjr0PWBVYBngOuBEgIi7P98/Nf6/tS56zJ/AT0vvwTa3XPgjYV9LmkvYG1mMBlPItcYKyhc3vgKMlLV1r+0+A1yLi+oj4JiJuBl4hfWHVuCYixuT9X+dtV0fEuIj4hPTlNS4i/p2/iG4F1ql5ckTcEBFT8/P/DLQGVpuH2C8CPgNqSkOHAydHxNsR8SVwOrBrLqHsCtwTEY/nfacCM+s6aS59HAQcGxGTIqI6Iv6bn7c7MDQiHsrXfB6wKCmRzYorIt6JiA+Bu0lJeH58DawIdI2IGRHxZB2xtiD9KDgxIj6LiInAn0mJuMYbEXFFbsO7FuhCqm6ck8ER8V5ETAKeAJ6OiOcjYgZwO7P/Da/Kr1vzfveR1Gku13VRRLwVEV/U3hER7wJH5DgvBPaLiM/mcj5rICcoW6hExEvAPcAJtXZ15dtSUY03SCWjGm/Vccr3Su5/Ucfj9jUPclXYy7l66GNSKWCphsQt6TBgU2CviKhJNCsCt+eqt49JJbZq0pdx19J4I+JzYE6dFJYitRWNq2PfbO9Lfu23mP19ebfk/nRKrnke/QYQMCJXKR40h1hbMfvfqvbfaVY8ETE9360vpgb9DSW1kHR2rlL9FJhYElN96vrclLqb1D76al1J2eafE5QtjE4DDmH2L7V3SF/4pVYAJpU8nu+p+3N7029I1WGLR8RiwCekL+SGPPcPwI4R8WnJrreAbSNisZJbm1wSmAwsX3KOtqRqvrpMAWaQqihrm+19yVVlyzP7+9JQn+d/25Zs61xzJyLejYhDIqIrcBhwaU27U61Ya0paNWr/ncplL2BHYEvSj4uV8vaav+GcPh9z+9ycSfpx0UXSnt8zRivhBGULnYh4HRjC7G0L9wI9Je2VG7J3B3qRSlsLQgfgG+ADoKWk3wEd5/YkScsDt5CqfsbW2n0ZcKakFfOxS0vaMe/7J7CdpA1ze9EZzOH/ay4VXQX8RVLXXFL4P0mt82v/RNIWSt3Gfw18Cfx3nq4+vc4HpESyT36NgyhJipJ2k1TTTvYR6Yt9Zq1zVOeYzpTUIV/7ccAN8xrPfOhAuvappCT7p1r73yO1izWYpI1J7Wf7AfsDgyV1q/9Z1lBOULawOgOYNSYqj9HZjvQFPJVU2tkuIqYsoNd7ALgfGEuqkprB3Kt+ALYgVdn9U9/25Kvptn0hcBfwoKTPgOGkDgJExBjgSFJnjMmkL/y363mdgcBoUkeOD4FzgKqIeBXYh9QxYQqpTW77iPiqgddd2yHA8aT3uDezJ7oBwNOSpuXrOnYOY5+OJpXGxgNP5mtsjJ5v15H+dpOA/5He71JXAr1ylesdczuZpI75nEfltr8n8jmunkunDmsgecFCMzMrIpegrIi2IXUzfp3vdoaA1H7xMPAiqdt5affrauCFfLurrFFakyZpG0mvSnpd0nc+h5JaK40be13S08pj5pTGi30h6YV8u6yxY28qypag8sC80gFsAyWdPg/PPyAP5HtB0iuSflWWQK1oWpDGAm1LakPaM/9b6jxS1crapKq+s0r2fUHqJt0X2KHcwVrTlLvDz/Y5zGPTSh0MfBQRPYDzSdWqNcZFRN98O7xRgm6CylmC+hLYRVKDuuHOwZCI6Av8EDg5Nzhb07YeqeQ0HvgK+Aep51WpXsAj+f5/6thv9n2tB7weEeNze11dn8MdSeOfIHVq2cJtTwtWORPUN8DlwHdKPrkI/EienuRhSSvUd6LcAP46acBeTW+nfylNRTNS0g/z9k1KitXP515CmypNaTI0F9cv07fTquwpabSklyTN+vWTG7LPlDRK0nBJy+btu+VjR0l6PG9rIWlQjuPFPN7F5l83Zu988DazdycHGAXsku/vTOqdVdMFuw1pxonhpFkazOZHQz6Hs47JA7s/4dvP4cr5O+gxzWFKLJu7crdBXQLsre+O1B4MXBsRa5OmF7movpPkBNaG1OYAqffT+RExgDTNyd/z9oHAkbnUtRGpugfSr6GjSb+8u5NKdl1JRfLNSdVBAyTVfKG1A4ZHRB/gcVLPJUizGGydt9dUHx0MfJJjGQAcImnlub4z9n0MJE2R83z+dxKp7QlS+9S6pDEvF1D32CCzcpoMrBAR65C60N+Ue/zZPCpbLz5J0yKivaQzSAPzvgDaR8TpkqYAXSLi6zw2Y3JELFXr+QeQJgedDKxO6sp5ed73PmkAYo2lSVPOHEX6RX0jcFtEvK20bssZEbFxfu5BpLaL/wA/jYj98vaDgd4RcZykL4E2ERF5PM2PIuLnubGzO2kcx20RMVXSP/P5aka8dwIOi4gHa13PoaR54KCqVX+1WQL7rh+s15/TTh7Itjum8Y4nDDwagLPPq3tat3bt2vLy80+yQs9+39l31d8uZOh9D/GvOxbUUKimpe/q9U3t17x9Pm0akydPpseqqwLw7ruTAejcucusY15/7TW6dOlCu/btiQhGvziKtdbuQ+1avtfGvkq3bsvRtl07rG7PP/fslIioPX0ZjTF9/AWkSRmvno/nDomIoyStSxorclee+6oK+EGea6vU2ZKGAj8GnpK0dd5eOwvPLSt/Hd9m7mry+xQRh0tanzTv27OS+pNGoR8dEQ/Ud8KcXC8HqGrXOVqvuW99hzdbL35ZRc811qbnj47hnQ8+ZY99DuSAU2+i9P1aslNbPvz0CyKCUw7fhuvuH0PrNfdlsQ6LMn3GV3z1dTVLdmrLhptszoX3vEnrNRev5xWbr8ceO2fuBzVT33zzDf3WWp1rbxxC167d2HTD9bnymhtYo1fvWcdcftml/G/MaC4Y/Ff+ecs/uPvO27n2xiFM+eADFl9iCVq0aMGECePZZotNeOCRJ1hiCf8onZOOi7aoPU0Z0AgJKiI+lHQLqSqsZjDef0kTRl5PmuL+ibmc4xlJ15NmCT6RNGPy0aQSFpL6RsQLkrpHxGhgtKQBpJLXx8B6udrtDdLkmZcDI4CLcieOj0i9xeY0+zL5dbpHxNOkwYjbkqaMeQA4QtIjuUTYE5iU506zeVRdPZNfnXcHd190CC2qqrj27hG8POE9Tj10K557+W2GPvE/Nu7fnTN+sS0R8OTz4/nloNsBWH2lZRh8wk+ZGUGVxHnX/odXJrxf4SuyhVHLli0ZdP5F7Lz9tlRXV7Pv/geyRq/e/PGM0+jXrz8/3m4H9jvgIA49aD/69O7J4osvwdXX3wTAU08+zpl/OJ1WrVpRVVXFBYMvdXKaT2Wv4sv3lwUmkKayPz1Pb3I1aZLGD4ADI+LNWs8/AFg3Io7Kj7uSSmKrkmaRvgRYg5RkH8+lm8HAZqTpVcYABwD/R+qK/BnQg1S194uImKk0b9ZJpFLQ0Ij4bR2x70qakeAASbfl1xdpHM4v8/0/kkboK1/PTnl27Dq5BGVF8L5LUFYQHRdt8WxErFt7e5OfSSK3QQ2MiO0qHUsNJygrAicoK4o5JSjPJGFmZoXUGJ0kKioiHiVNh2NmZgsRl6DMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQWs5ph6SO9T0xIj5d8OGYmZklc0xQwBggAJVsq3kcwApljMvMzJq5OSaoiFi+MQMxMzMr1aA2KEl7SDop319OUv/yhmVmZs3dXBOUpIuBzYB986bpwGXlDMrMzKy+NqgaG0REP0nPA0TEh5IWKXNcZmbWzDWkiu9rSVWkjhFIWhKYWdaozMys2WtIgroE+BewtKTfA08C55Q1KjMza/bmWsUXEddJehbYMm/aLSJeKm9YZmbW3DWkDQqgBfA1qZrPs0+YmVnZNaQX38nAzUBXYDngJkknljswMzNr3hpSgtoPWCcipgNIOhN4HjirnIGZmVnz1pDqusnMnsha5m1mZmZlU99kseeT2pw+BMZIeiA/3goY2TjhmZlZc1VfFV9NT70xwNCS7cPLF46ZmVlS32SxVzZmIGZmZqXm2klCUnfgTKAX0KZme0T0LGNcZmbWzDWkk8Q1wNWkdaC2BW4BhpQxJjMzswYlqLYR8QBARIyLiFNIicrMzKxsGjIO6ss8Wew4SYcDk4AO5Q3LzMyau4YkqF8B7YBjSG1RnYCDyhmUmZlZQyaLfTrf/YxvFy00MzMrq/oG6t5OXgOqLhGxS1kiMjMzo/4S1MWNFkVzEzPhqy8qHYU1c61aemECK7b6Buo+3JiBmJmZlfJPKDMzKyQnKDMzK6QGJyhJrcsZiJmZWamGrKi7nqTRwGv5cR9Jg8semZmZNWsNKUFdBGwHTAWIiFHAZuUMyszMrCEJqioi3qi1rbocwZiZmdVoyFRHb0laDwhJLYCjgbHlDcvMzJq7hpSgjgCOA1YA3gN+kLeZmZmVTUPm4nsf2KMRYjEzM5ulISvqXkEdc/JFxKFlicjMzIyGtUH9u+R+G2Bn4K3yhGNmZpY0pIpvtuXdJV0PPFm2iMzMzJi/qY5WBpZd0IGYmZmVakgb1Ed82wZVBXwInFDOoMzMzOpNUJIE9AEm5U0zI2KOixiamZktKPVW8eVkdG9EVOebk5OZmTWKhrRBvSBpnbJHYmZmVmKOVXySWkbEN8A6wEhJ44DPAZEKV/0aKUYzM2uG6muDGgH0A3ZopFjMzMxmqS9BCSAixjVSLGZmZrPUl6CWlnTcnHZGxF/KEI+ZmRlQf4JqAbQnl6TMzMwaU30JanJEnNFokZiZmZWor5u5S05mZlYx9SWoLRotCjMzs1rmmKAi4sPGDMTMzKzU/MxmbmZmVnZOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUFY4P9pgDUbdfiov3XkaAw/80Xf2r9Blce697GhGDDmRB644lm7LLAbAxuuuyvB/nDDr9tHw89l+07UbO3xrIh584H7W7r0avVfvwaBzz/7O/i+//JJ99tqd3qv3YKMN1ueNiRMBGDliBOv378v6/fuyXr8+3HnH7Y0cedOhiKh0DHMkqRoYDbQEJgD7RsTHlY3q+6tqu0y0Xu1nlQ6jkKqqxOg7fsdPjriYSe99zJM3Hs/+J17DK+PfnXXMjecexL1PjOHGu59mkwE92W+HH3DwqdfNdp7FO7blpbtOo8c2p/DFjK8b+zIWCh+NvLjSIRRWdXU1a/XqydD7HqLbcsux4Q8GcO0NN7NGr16zjvnbXy/lpdEvMvjSy7hlyD+4687bueGmIUyfPp1FFlmEli1bMnnyZNbv34fxb75Dy5YtK3hFxbZoKz0bEevW3l70EtQXEdE3ItYEPgSOrHRAVl4D1lyJcW9NYeKkqXz9TTW3PvAc29UqBa2+ShceG/EqAI+NHMt2m671nfPsvOU6PPjU/5ycbL6MHDGC7t17sPIqq7DIIouw2+57cM/dd852zD1338ne++4PwC4/3ZVHH3mYiKBt27azktGXM2YgqdHjbyqKnqBKDQO61TyQdLykkZJelPT7vK2dpKGSRkl6SdLueftESedKGi1phKQeeftKkh7J53hY0gp5+zWSLpL0X0njJe2at3eR9LikF/L5N8rbt5I0TNJzkm6V1L6R35smo+synXj7vY9mPZ703kd0W7rTbMeMHjuJHTfvC8COm/ehY/tFWaJTu9mO2W3rftxy/7PlD9iapHfemcRyyy0/63G3bssxadKk7x6zfDqmZcuWdOzUialTpwIw4umn6denN+uusxYXXXKZS0/zaaFIUJJaAFsAd+XHWwGrAusBfYH+kjYGtgHeiYg+udR1f8lpPomItYCLgQvytsHAtRGxNnAjcFHJ8V2ADYHtgJoK6L2AByKiL9AHeEHSUsApwJYR0Q94BjhuQV6/ze7E829no/49GHbzb9mofw8mvfcR1dUzZ+3vvFRHeq/alYeG/a+CUVpztt766/PcqDE8OWwkg845ixkzZlQ6pIXSwtIG1Q14GdgsIqolnQfsCtS0R7UHzgKeAB4EhgD3RMQT+TwTgc0jYrykVsC7EbGkpClAl4j4Om+fHBFLSboGeCgibszP/ywiOuQkeBVwA3BHRLwgaTvgGuDtHMsiwLCIOLjWtRwKHJofrga8uuDeqaZjiy22aHf66ad33WijjV4D+NOf/tQZ4KSTTnq31qFLAVM6duxYNXbs2DU7d+78Ys2OU045ZZlevXotutdee73ReJFbE9MO6Aq8lh93zv+Wfg5XBaYDNUWrPsCoOs7Vk/T9MH3Bh9lkrBgRS39na0QU9gZMy/+2JSWfY/LjPwOHzeE5SwD7AI8Bv8vbJgIr5/utgCn5/hSgVR3brwF2rR1Hvt8VOAR4AdgP2B64udLvVRO6tYyI8RGxckQsEhGjIqJ3rWOWqqqqeibfPzMizqi1f3hEbFaAa/FtIb2ROmaNB1Ym/egcBfSudcyRwPv5/h7ALfn+ykDLfH9F4B1gqUpf08J4Wyiq+CJiOnAM8GtJLYEHgINq2nokdZO0jKSuwPSIuAEYBPQrOc3uJf8Oy/f/S/pgAexNSoJzJGlF4L2IuAL4ez7/cOCHJe1a7ST1/F4X3Lx9AxxF+hu/DNwCjAHOAHbIx2w6fvz4NYGxwLLAmSXPXwlYnvQDxWy+RMR3PocRMUbSGZJqPodXAi0lvU6q1j8hb98QGCXpBeB24BcRMaVxr6BpKHoV37SIaF/y+G7SB+V6SccCP8+7ppFKTT1IiWkm8DVwREQ8k6v4hgDbAl8Ce0bE6znhXE2qLvoAODAi3sxVfPdExD9L45C0P3B8Pvc0YL+ImCBpc+AcoHWO55SIuKtMb4sBkp6JOrqlmjUmfw7Lq9AJakHJCWpd/4ppOiQdGhGXVzoOa978OSwvJygzMyukZpGgzMxs4bNQdJIwM7PmxwnKFlryHDJmTZoTlC00ahKSpE6S2oTrp82aNLdB2UJF0k6kIQUzgX8B90XEp5WNypobSfIPpPJzCcoWGpIGACcCh5ES1AGkMWlmjaYmOUnaSNL+kn4iqUOl42qKnKCs8EramlYijd7fgDSFzBER8YWkznN6rtmClpPTDsBfgE7AQNL0Z7aAOUFZYdVKTACTgR2BU4G9ImKipJ8CF0pqW4EQrRmS1AbYGdiaNAlsW+AmSVV55QVbQJygrLDyL9VtgbskrQy8Qprg9zFgRUmbAacD1+f5Gs3KoqSDTgvSfJEB/An4JenH0rvAVsCAigXZBDlBWWFJWh+4EDg4IibkmUBOAD4ntT/9AjgxIu5xl3Mrl5I2px8Bu+eJZB8CtgQujIhxeSmei4DqSsba1HiZRyuckh5SXUjrb31WMjnw48AZEfGepE4R8Yl7VFk55eS0DenHUs2abv8htUGdnEvyWwC/ioiRFQqzSXI3cyuMkl+qrSPiy7yEyRBgKvBP0vIoZwKXRcR9TkzWGHIPvbuAcyLifkmbAt2BCaTFCpcBPou0gKk/kwuQE5QVSl6h+ChSO9NdpBVNW0bEdEmrALeRlkV5voJhWjMj6XdAb1Kt0xek4Q0fRMRvKhpYE+c2KCsMSasBBwN3AyK1N22dk9P2wJ3A6U5OVk4lHSL6StpMUifgCuBB4NyI2Ie0kOZa7j1aXi5BWcXlL4TewKOkxR4vy4tJbg5sQqrmGwasHhHDXY1i5ZY7RFxLamvaCNgoIt7I+zYBBpM66AytXJRNn0tQVnGRvESq1jsxb3uD9It1OKnHHhExvOb4ykRqzYGk1YFdgZ9GxN6kVbeHS1oh/5j6MXBSRAx179HycgnKKqKkQ8SawHLAcxHxvqRrgD4RsU4+bjmAiHi7ctFacyCpClgEOB9YDzg7Im7N+04Dfg30At6LiK9dki8/JyirGEk7Ar8H3gKmA89ExCBJVwE/jIjVKhqgNQslP5baRMQMSR2B35EG5A6pafOUdCbwSEQ8XMl4mxMnKKsISe2AG0idHkblrrvbA09ExB2S7gAGRcRTlYzTmoc8zulI4F3geeBvpJLUZ8AdpeObXHJqPG6DskqpApYljSeBNMbpPWAbgIjYycnJGkOeseQ84O+kH02/BE4mTQLbGdgll6oAt4E2Js8kYY2ipBplZeCLiHhX0l+ArSW9HxFPSnoW6CupPTA9ImZWNmprJjoB90fEnQCS1gWeII3DOw1YzGuOVYYTlJVdSXLaFjgb+FjSMFLb0zDgEkkPknpOHRkR0yoYrjVxdVTRzQC2kNQqIr6OiE8lPUxKTC+QZiy3CnCCsrLLyWkAqY5/D6AFqZfUOsB1pDn2VgRujYgRruO3cir5sbQx8ClwMam09Jyk/YClSTOTD6lclAZOUNYIcoeIA0kJ6bWI+EbS56SFB3tGxI3ArEZoJycrh5KSfG/gHNL4ppWBUaTP5kfAMUA34LcR8XTFgjXACcrKpOTLYPWIeEXSJaQOEZdIOjwiJkiaQPpiuNGlJiu3/HncgNSuNDgirgCQ9A5wH7ApaY69thHxuT+TledefFYWJdUo90taMyLGkAY6LgI8KmkXYBfSujouNVnZ1Fps8G1gFWCzvK0qIs4GxgGL51lNPgd/JovACcrKQlIf4AJgl4h4SdLSpE4RfyYNyv0NcFxEPCDJJXkri5KS/DbACRHxJmkowzqSTgG65lLVJkDH+s5ljc8Dda0sclfdnUm99NYidY4YS1om+yvgMFJp6siI8CqkVjaStiItNnhIRDyZt60I3E6aLeJJ0gwR91QuSquLS1C2QJRUoyyexzGNIc2xdyjwBrAdMAXolav7riZ17126MhFbUyepSlJr0o+hM/JYu50lnUuaU29roDVpXN49yioZs83OJShbYPKaTQNJiWg08EegKiK+krQGcBNwTEQ8kb8IWkXEV5WL2JoDSQeSepHOAF4lfT67R8R+klYllaDOiogLKhim1cEJyhaIPF3MBcBuwO6kX63r5N5QW5Cq9s7K8+y5d5SVRUmb00aksXbPAJ8DbYGpETEmtzkNAnbOM+j3IPWJGFe5yK0uruKz+ZKXJphtE2lsyQakJLV1Tk49SfPsHezkZOVW0iHictIg3L8BG0bE4zk5bUGac+/snJxaRMTrTk7F5N5TNs/ygm77Swrg/Ij4AFgC+APwCbBVni5mC+BYYP9ICxK6666VlaQOpPbO7YElSdV6Q/K+5YAewK8j4r78Y8kddArMCcrmSU5ON5Jmfd4JWAHYJyLuVVoKewdgpbwQ4cmkEfkfVSxga9IkdSVN9jotIt6KiM8kvUmanbwLsENETM5rj70PXBURX4N/LC0MXMVnDSZpCeBfwKMRcXD7YqcAAAYySURBVH5EbAIsIWlvgIj4LXAzcATpV+xxNb2jKha0NVn5x9LdwGDgLEk/y7smknqHDoqIN/OQh3OB1jXJyRYO7iRhDSapG6nbeAfgzoh4LC+ZsRhQDVwCvBkRH0pqHRFfVjBca8Ik9SKV5I8j9czbGVgmIk6TtDjwK1J13mKkufVOjYi7KhWvzR8nKJsnucfTjqSqvWrSWJLfAz8DvgQ2BPoAn7l+38pF0obA4xFRlR/3AC4CTgEmRMRHufqvM2ltsVfcQWfh4wRl8yx/GexK6kr+64i4rWRfd/eIssaQe+tdGhGrSNqTNFvEW6SZSsYBV0fEw5WM0b4fd5KwBqv5BRoRr0u6iVSC2lDSpxHx73zY+AqGaM1IRNwv6ShJ04CXI2KZ3E7aHvgt8GFlI7TvyyUom6O6qkQktYyIb/L9HqSqvVWAgRHxcQXCtGZO0ubAdRGxXKVjsQXLCcrqVDIif1PSvGUiVZlMV14aOx/XA6iOiAkVDNeauVzddx2wmoc1NB1OUDZHeRboQaSBjr1IiwuuHxHT8gh8d4KwwpD0Y1KHiEcrHYstGE5QNoukpYCuEfFifnwx8FxEXJUfDwZWA35cU81nVjTurdd0eKCuASBpEeBg4FBJ/fLmz4HFSw47mbQiaetGDs+swZycmg4nKAMgL3vxKPABsEduW/oHcFKeJgZg7XzzyqNmVnau4mvmJC0PrBERD+bHKwGHkFa7PY80Gv/vpDVz/o80t97QigRrZs2KE1Qzlqv1XgOWB64gTaZ5G9AG2Ig0Cef5pJL2okC7iPif6/jNrDE4QTVzkvoAdwHPA1eR2plGkHrtTQWmA2dGxGsVC9LMmiW3QTVzETGKtETGJqQfLDUr475O6iCxH+4UYWYV4BKUASBpPeBB4MSI+KukqoiYKWllD8I1s0rwXHwGQESMkLQlcG9eKuOCvGsieGyJmTU+l6BsNpLWB/4N9AbeclIys0pxgrLvkNQxIj6tdBxm1ry5k4TV5TNI1XqVDsTMmi+XoMzMrJBcgjIzs0JygjIzs0JygjIzs0JygjJrJJKqJb0g6SVJt0pq+z3Otamke/L9HSSdUM+xi0n6xXy8xumSBjZ0e61jrpG06zy81kqSXprXGK1pc4IyazxfRETfiFgT+Ao4vHSnknn+PxkRd0XE2fUcshgwzwnKrNKcoMwq4wmgRy45vCrpOuAlYHlJW0kaJum5XNJqDyBpG0mvSHoO2KXmRJIOyKsfI2lZSbdLGpVvGwBnA91z6W1QPu54SSMlvSjp9yXnOlnSWElPklZPrpekQ/J5Rkn6V61S4ZaSnsnn2y4f30LSoJLXPuz7vpHWdDlBmTUySS2BbYHRedOqwKUR0Zu0ivEpwJYR0Q94BjhOUhvSkijbA/2BznM4/UXAYxHRB+gHjAFOAMbl0tvxkrbKr7ke0BfoL2ljSf2BPfK2HwMDGnA5t0XEgPx6L5NWZa6xUn6NnwCX5Ws4GPgkIgbk8x8iaeUGvI41Q56Lz6zxLCrphXz/CeBKoCvwRkQMz9t/QFrq5Kk8TnoRYBiwOjChZtkTSTcAh9bxGpuTZqAnIqqBTyQtXuuYrfLt+fy4PSlhdQBuj4jp+TXuasA1rSnpj6RqxPbAAyX7bomImcBrksbna9gKWLukfapTfu2xDXgta2acoMwazxcR0bd0Q05Cn5duAh6KiD1rHTfb874nAWdFxN9qvcYv5+Nc1wA7RcQoSQcAm5bsqz0LQOTXPjoiShNZzUrOZrNxFZ9ZsQwHfiipB4CkdpJ6Aq8AK0nqno/bcw7Pfxg4Ij+3haROpKmrOpQc8wBwUEnbVjdJywCPAztJWlRSB1J14tx0ACZLagXsXWvfbpKqcsyrAK/m1z4iH4+knpLaNeB1rBlyCcqsQCLig1wSuVlSzUKRp0TEWEmHAkMlTSdVEXao4xTHApdLOhioBo6IiGGSnsrduO/L7VBrAMNyCW4asE9EPCdpCDAKeB8Y2YCQTwWeBj7I/5bG9CZpdeaOwOERMUPS30ltU8/luR4/AHZq2LtjzY3n4jMzs0JyFZ+ZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRXS/wPSK2JRjqFwgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils as my_utils\n",
    "ax = plot_confusion_matrix(y_test, (lr.predict(X_test) ).astype(np.int32), classes=np.array(['No Response', 'Response']), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "Notice the import for the confusion matrix:\n",
    "```python\n",
    "import utils as my_utils\n",
    "```\n",
    "There are methods in there used throughout this notebook. They are pretty self explanatory so I will not go into them, but feel free to check them out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of ML so far:\n",
    "So far we created two basic models, a linear model and a random forest model for regression and classification. We only applied the machine learning on a basic two feature data set where we charatized both cells and drugs by their identity, passing them to the machine learning algorithm aas simple ordinal labelings to identify the label (where we typically would use strings instead of numbers). \n",
    "\n",
    "We applied five fold cross validaiton, and one should also have seen how composable the models are. For instance, we could have done this entire first past as simply as this. Further this example illistates how ML code is extremely composable and iterable. In this example, we combine everything into a simple summary of tables over regression/classif understandings of the data, over various model types, and over different cross folds. Feel free to play around with this, extending the model list to include things like SVMs or gradient boosting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/austin/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Selection Results, classif:\n",
      "+----+----------+----------+-----------+-------------+----------+----------+----------+----------+----------+\n",
      "|    |      acc |   balacc |       mcc |   precision |   recall |       tp |       fp |       tn |       fn |\n",
      "|----+----------+----------+-----------+-------------+----------+----------+----------+----------+----------|\n",
      "|  0 | 0.690295 | 0.539585 | 0.0657106 |   0.549778  | 0.360415 | 0.360415 | 0.281244 | 0.718756 | 0.718756 |\n",
      "|  1 | 0.625038 | 0.554821 | 0.0677625 |   0.0506765 | 0.471396 | 0.471396 | 0.361755 | 0.638245 | 0.638245 |\n",
      "+----+----------+----------+-----------+-------------+----------+----------+----------+----------+----------+\n",
      "Model Selection Results, reg:\n",
      "+----+-----------+----------+----------------------+\n",
      "|    |        r2 |      mae |   mean_squared_error |\n",
      "|----+-----------+----------+----------------------|\n",
      "|  0 | -0.492116 | 0.136996 |            0.037855  |\n",
      "|  1 | -0.096791 | 0.128003 |            0.0247447 |\n",
      "+----+-----------+----------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import utils as my_utils\n",
    "from tabulate import tabulate\n",
    "\n",
    "classif_models = [sklearn.ensemble.RandomForestClassifier, sklearn.linear_model.LogisticRegression]\n",
    "reg_models = [sklearn.ensemble.RandomForestRegressor, sklearn.linear_model.LinearRegression]\n",
    "\n",
    "model_perf = {}\n",
    "for use_binned, problem_type in [(True, classif_models), (False, reg_models)]:\n",
    "    y_ = (y <= CUTOFF).astype(np.int32) if use_binned else y\n",
    "    score_func = my_utils.get_bclassif_metrics if use_binned else my_utils.get_regression_metrics\n",
    "    model_scores = []\n",
    "    for model in problem_type:\n",
    "        cv = (sklearn.model_selection.StratifiedKFold if use_binned else sklearn.model_selection.KFold)(2)\n",
    "        avg_metrics = my_utils.DictAvg()\n",
    "        for train, test in cv.split(X,y_):\n",
    "            X_train, X_test, y_train, y_test = X[train], X[test], y_[train], y_[test]\n",
    "            m = model()\n",
    "            m.fit(X_train, y_train)\n",
    "            avg_metrics(score_func(y_test, m.predict(X_test)))\n",
    "        model_scores.append(avg_metrics)\n",
    "\n",
    "    model_perf['classif' if use_binned else 'reg'] = model_scores\n",
    "\n",
    "for key in model_perf.keys():\n",
    "    print(\"Model Selection Results, %s:\" % key)\n",
    "    tmp_scores = pd.DataFrame.from_dict([v.avg() for v in model_perf[key]])\n",
    "    print(tabulate(tmp_scores, tablefmt='psql',headers=tmp_scores.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in Feature Data for one variable\n",
    "This was not a particularly useful exercise towards getting a good model, but rather an attempt at the most basic and general approach to this problem. Let's start by increasing the complexity by introducing RNA-seq features. Again we assume these features come pre-scaled. We will think again we do not have any drug features, just the name.  \n",
    "\n",
    "There are two options to think about now that we have features:\n",
    "- By drug model: we create, say, 100 models one for each drug. One of these models, say the \"Paclitaxel model,\" takes in the RNA-seq of a cell, and predicts whether it will respond or not (classification, or it can predict the AUC, regression) **(Single task model)**\n",
    "- Combined model: this model takes both a drug name and the cell RNA-seq and performs the same task.  **(Multitask model)**\n",
    "\n",
    "We call the latter type of model a multi-task model as the features for drugs are like lookup tables to the model. The model gets some vector of RNA-seq and a drug name, it can use that drug name to look up some small model it has internally to then use that prediction on. Classical machine learning is very good at multi-tasking, but deep learning is. We will explore this distinction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>AARS</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>ABCF3</th>\n",
       "      <th>ABHD4</th>\n",
       "      <th>ABHD6</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACAA1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMIZ1</th>\n",
       "      <th>ZMYM2</th>\n",
       "      <th>ZNF131</th>\n",
       "      <th>ZNF274</th>\n",
       "      <th>ZNF318</th>\n",
       "      <th>ZNF395</th>\n",
       "      <th>ZNF451</th>\n",
       "      <th>ZNF586</th>\n",
       "      <th>ZNF589</th>\n",
       "      <th>ZW10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE.22RV1</td>\n",
       "      <td>5.797</td>\n",
       "      <td>4.390</td>\n",
       "      <td>2.350</td>\n",
       "      <td>3.383</td>\n",
       "      <td>5.930</td>\n",
       "      <td>3.684</td>\n",
       "      <td>0.925</td>\n",
       "      <td>2.404</td>\n",
       "      <td>3.744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.421</td>\n",
       "      <td>3.158</td>\n",
       "      <td>1.918</td>\n",
       "      <td>2.498</td>\n",
       "      <td>3.146</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.9770</td>\n",
       "      <td>2.1130</td>\n",
       "      <td>2.1210</td>\n",
       "      <td>2.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLE.2313287</td>\n",
       "      <td>6.516</td>\n",
       "      <td>3.787</td>\n",
       "      <td>2.020</td>\n",
       "      <td>4.848</td>\n",
       "      <td>5.844</td>\n",
       "      <td>5.460</td>\n",
       "      <td>2.137</td>\n",
       "      <td>1.829</td>\n",
       "      <td>4.350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.910</td>\n",
       "      <td>3.113</td>\n",
       "      <td>2.176</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.344</td>\n",
       "      <td>2.037</td>\n",
       "      <td>3.0550</td>\n",
       "      <td>1.8590</td>\n",
       "      <td>2.0430</td>\n",
       "      <td>3.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLE.253J</td>\n",
       "      <td>4.965</td>\n",
       "      <td>3.947</td>\n",
       "      <td>1.747</td>\n",
       "      <td>3.840</td>\n",
       "      <td>5.480</td>\n",
       "      <td>5.156</td>\n",
       "      <td>1.124</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.421</td>\n",
       "      <td>2.021</td>\n",
       "      <td>1.264</td>\n",
       "      <td>2.791</td>\n",
       "      <td>1.440</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>1.0830</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>1.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLE.253JBV</td>\n",
       "      <td>5.203</td>\n",
       "      <td>3.586</td>\n",
       "      <td>2.270</td>\n",
       "      <td>4.600</td>\n",
       "      <td>5.812</td>\n",
       "      <td>4.900</td>\n",
       "      <td>1.523</td>\n",
       "      <td>2.252</td>\n",
       "      <td>2.818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818</td>\n",
       "      <td>2.205</td>\n",
       "      <td>1.451</td>\n",
       "      <td>2.703</td>\n",
       "      <td>2.234</td>\n",
       "      <td>2.008</td>\n",
       "      <td>1.1110</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>1.1340</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLE.42MGBA</td>\n",
       "      <td>5.260</td>\n",
       "      <td>4.080</td>\n",
       "      <td>1.178</td>\n",
       "      <td>5.336</td>\n",
       "      <td>4.914</td>\n",
       "      <td>4.750</td>\n",
       "      <td>2.336</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.678</td>\n",
       "      <td>...</td>\n",
       "      <td>3.150</td>\n",
       "      <td>1.499</td>\n",
       "      <td>2.404</td>\n",
       "      <td>3.219</td>\n",
       "      <td>1.789</td>\n",
       "      <td>2.387</td>\n",
       "      <td>2.0550</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>3.219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sample   AARS  ABCB6  ABCC5  ABCF1  ABCF3  ABHD4  ABHD6   ABL1  \\\n",
       "0    CCLE.22RV1  5.797  4.390  2.350  3.383  5.930  3.684  0.925  2.404   \n",
       "1  CCLE.2313287  6.516  3.787  2.020  4.848  5.844  5.460  2.137  1.829   \n",
       "2     CCLE.253J  4.965  3.947  1.747  3.840  5.480  5.156  1.124  2.000   \n",
       "3   CCLE.253JBV  5.203  3.586  2.270  4.600  5.812  4.900  1.523  2.252   \n",
       "4   CCLE.42MGBA  5.260  4.080  1.178  5.336  4.914  4.750  2.336  3.018   \n",
       "\n",
       "   ACAA1  ...  ZMIZ1  ZMYM2  ZNF131  ZNF274  ZNF318  ZNF395  ZNF451  ZNF586  \\\n",
       "0  3.744  ...  1.421  3.158   1.918   2.498   3.146   2.885  2.9770  2.1130   \n",
       "1  4.350  ...  1.910  3.113   2.176   2.630   2.344   2.037  3.0550  1.8590   \n",
       "2  2.940  ...  1.421  2.021   1.264   2.791   1.440   1.451  0.9653  1.0830   \n",
       "3  2.818  ...  1.818  2.205   1.451   2.703   2.234   2.008  1.1110  0.9320   \n",
       "4  3.678  ...  3.150  1.499   2.404   3.219   1.789   2.387  2.0550  0.9116   \n",
       "\n",
       "   ZNF589   ZW10  \n",
       "0  2.1210  2.920  \n",
       "1  2.0430  3.049  \n",
       "2  0.6484  1.126  \n",
       "3  1.1340  1.606  \n",
       "4  0.7485  3.219  \n",
       "\n",
       "[5 rows x 943 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_T = pd.read_csv(\"/Users/austin/data/dose_response_data/data/cell/combined_rnaseq_data_lincs1000_combat\", sep='\\t')\n",
    "df_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah but we want that first column name to be CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL</th>\n",
       "      <th>AARS</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>ABCF3</th>\n",
       "      <th>ABHD4</th>\n",
       "      <th>ABHD6</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACAA1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMIZ1</th>\n",
       "      <th>ZMYM2</th>\n",
       "      <th>ZNF131</th>\n",
       "      <th>ZNF274</th>\n",
       "      <th>ZNF318</th>\n",
       "      <th>ZNF395</th>\n",
       "      <th>ZNF451</th>\n",
       "      <th>ZNF586</th>\n",
       "      <th>ZNF589</th>\n",
       "      <th>ZW10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE.22RV1</td>\n",
       "      <td>5.797</td>\n",
       "      <td>4.390</td>\n",
       "      <td>2.350</td>\n",
       "      <td>3.383</td>\n",
       "      <td>5.930</td>\n",
       "      <td>3.684</td>\n",
       "      <td>0.925</td>\n",
       "      <td>2.404</td>\n",
       "      <td>3.744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.421</td>\n",
       "      <td>3.158</td>\n",
       "      <td>1.918</td>\n",
       "      <td>2.498</td>\n",
       "      <td>3.146</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.9770</td>\n",
       "      <td>2.1130</td>\n",
       "      <td>2.1210</td>\n",
       "      <td>2.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLE.2313287</td>\n",
       "      <td>6.516</td>\n",
       "      <td>3.787</td>\n",
       "      <td>2.020</td>\n",
       "      <td>4.848</td>\n",
       "      <td>5.844</td>\n",
       "      <td>5.460</td>\n",
       "      <td>2.137</td>\n",
       "      <td>1.829</td>\n",
       "      <td>4.350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.910</td>\n",
       "      <td>3.113</td>\n",
       "      <td>2.176</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.344</td>\n",
       "      <td>2.037</td>\n",
       "      <td>3.0550</td>\n",
       "      <td>1.8590</td>\n",
       "      <td>2.0430</td>\n",
       "      <td>3.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLE.253J</td>\n",
       "      <td>4.965</td>\n",
       "      <td>3.947</td>\n",
       "      <td>1.747</td>\n",
       "      <td>3.840</td>\n",
       "      <td>5.480</td>\n",
       "      <td>5.156</td>\n",
       "      <td>1.124</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.421</td>\n",
       "      <td>2.021</td>\n",
       "      <td>1.264</td>\n",
       "      <td>2.791</td>\n",
       "      <td>1.440</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>1.0830</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>1.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLE.253JBV</td>\n",
       "      <td>5.203</td>\n",
       "      <td>3.586</td>\n",
       "      <td>2.270</td>\n",
       "      <td>4.600</td>\n",
       "      <td>5.812</td>\n",
       "      <td>4.900</td>\n",
       "      <td>1.523</td>\n",
       "      <td>2.252</td>\n",
       "      <td>2.818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818</td>\n",
       "      <td>2.205</td>\n",
       "      <td>1.451</td>\n",
       "      <td>2.703</td>\n",
       "      <td>2.234</td>\n",
       "      <td>2.008</td>\n",
       "      <td>1.1110</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>1.1340</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLE.42MGBA</td>\n",
       "      <td>5.260</td>\n",
       "      <td>4.080</td>\n",
       "      <td>1.178</td>\n",
       "      <td>5.336</td>\n",
       "      <td>4.914</td>\n",
       "      <td>4.750</td>\n",
       "      <td>2.336</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.678</td>\n",
       "      <td>...</td>\n",
       "      <td>3.150</td>\n",
       "      <td>1.499</td>\n",
       "      <td>2.404</td>\n",
       "      <td>3.219</td>\n",
       "      <td>1.789</td>\n",
       "      <td>2.387</td>\n",
       "      <td>2.0550</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>3.219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CELL   AARS  ABCB6  ABCC5  ABCF1  ABCF3  ABHD4  ABHD6   ABL1  \\\n",
       "0    CCLE.22RV1  5.797  4.390  2.350  3.383  5.930  3.684  0.925  2.404   \n",
       "1  CCLE.2313287  6.516  3.787  2.020  4.848  5.844  5.460  2.137  1.829   \n",
       "2     CCLE.253J  4.965  3.947  1.747  3.840  5.480  5.156  1.124  2.000   \n",
       "3   CCLE.253JBV  5.203  3.586  2.270  4.600  5.812  4.900  1.523  2.252   \n",
       "4   CCLE.42MGBA  5.260  4.080  1.178  5.336  4.914  4.750  2.336  3.018   \n",
       "\n",
       "   ACAA1  ...  ZMIZ1  ZMYM2  ZNF131  ZNF274  ZNF318  ZNF395  ZNF451  ZNF586  \\\n",
       "0  3.744  ...  1.421  3.158   1.918   2.498   3.146   2.885  2.9770  2.1130   \n",
       "1  4.350  ...  1.910  3.113   2.176   2.630   2.344   2.037  3.0550  1.8590   \n",
       "2  2.940  ...  1.421  2.021   1.264   2.791   1.440   1.451  0.9653  1.0830   \n",
       "3  2.818  ...  1.818  2.205   1.451   2.703   2.234   2.008  1.1110  0.9320   \n",
       "4  3.678  ...  3.150  1.499   2.404   3.219   1.789   2.387  2.0550  0.9116   \n",
       "\n",
       "   ZNF589   ZW10  \n",
       "0  2.1210  2.920  \n",
       "1  2.0430  3.049  \n",
       "2  0.6484  1.126  \n",
       "3  1.1340  1.606  \n",
       "4  0.7485  3.219  \n",
       "\n",
       "[5 rows x 943 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_colnames = df_T.columns.tolist()\n",
    "cell_colnames[0] = 'CELL'\n",
    "df_T.columns = cell_colnames\n",
    "df_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>AARS</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>ABCF3</th>\n",
       "      <th>ABHD4</th>\n",
       "      <th>ABHD6</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACAA1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMYM2</th>\n",
       "      <th>ZNF131</th>\n",
       "      <th>ZNF274</th>\n",
       "      <th>ZNF318</th>\n",
       "      <th>ZNF395</th>\n",
       "      <th>ZNF451</th>\n",
       "      <th>ZNF586</th>\n",
       "      <th>ZNF589</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>FEATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3957</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>3.960</td>\n",
       "      <td>2.041</td>\n",
       "      <td>1.770</td>\n",
       "      <td>4.496</td>\n",
       "      <td>4.848</td>\n",
       "      <td>5.445</td>\n",
       "      <td>1.2280</td>\n",
       "      <td>2.404</td>\n",
       "      <td>3.424</td>\n",
       "      <td>...</td>\n",
       "      <td>2.553</td>\n",
       "      <td>2.572</td>\n",
       "      <td>2.2480</td>\n",
       "      <td>1.669</td>\n",
       "      <td>1.379</td>\n",
       "      <td>2.100</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>2.460</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2828</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>5.582</td>\n",
       "      <td>1.798</td>\n",
       "      <td>1.645</td>\n",
       "      <td>4.617</td>\n",
       "      <td>6.460</td>\n",
       "      <td>5.406</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>1.729</td>\n",
       "      <td>3.756</td>\n",
       "      <td>...</td>\n",
       "      <td>3.736</td>\n",
       "      <td>2.334</td>\n",
       "      <td>2.8540</td>\n",
       "      <td>1.854</td>\n",
       "      <td>2.549</td>\n",
       "      <td>2.111</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>1.1180</td>\n",
       "      <td>2.793</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>617</td>\n",
       "      <td>0.7810</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.244</td>\n",
       "      <td>1.383</td>\n",
       "      <td>6.707</td>\n",
       "      <td>5.930</td>\n",
       "      <td>4.285</td>\n",
       "      <td>1.7680</td>\n",
       "      <td>1.658</td>\n",
       "      <td>3.490</td>\n",
       "      <td>...</td>\n",
       "      <td>3.049</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.8460</td>\n",
       "      <td>2.201</td>\n",
       "      <td>3.309</td>\n",
       "      <td>2.190</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>1.5810</td>\n",
       "      <td>3.123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6024</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>3.643</td>\n",
       "      <td>2.258</td>\n",
       "      <td>1.564</td>\n",
       "      <td>4.406</td>\n",
       "      <td>5.480</td>\n",
       "      <td>3.965</td>\n",
       "      <td>2.2320</td>\n",
       "      <td>2.465</td>\n",
       "      <td>4.540</td>\n",
       "      <td>...</td>\n",
       "      <td>2.994</td>\n",
       "      <td>1.978</td>\n",
       "      <td>-0.9106</td>\n",
       "      <td>1.951</td>\n",
       "      <td>2.781</td>\n",
       "      <td>2.055</td>\n",
       "      <td>-0.1396</td>\n",
       "      <td>2.1660</td>\n",
       "      <td>2.387</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2179</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>4.940</td>\n",
       "      <td>3.572</td>\n",
       "      <td>2.998</td>\n",
       "      <td>5.610</td>\n",
       "      <td>6.210</td>\n",
       "      <td>3.742</td>\n",
       "      <td>2.6170</td>\n",
       "      <td>3.291</td>\n",
       "      <td>4.030</td>\n",
       "      <td>...</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.037</td>\n",
       "      <td>2.4800</td>\n",
       "      <td>2.887</td>\n",
       "      <td>2.504</td>\n",
       "      <td>2.270</td>\n",
       "      <td>1.2280</td>\n",
       "      <td>1.8050</td>\n",
       "      <td>1.628</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 944 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC   AARS  ABCB6  ABCC5  ABCF1  ABCF3  ABHD4   ABHD6   ABL1  ACAA1  \\\n",
       "3957  0.8682  3.960  2.041  1.770  4.496  4.848  5.445  1.2280  2.404  3.424   \n",
       "2828  0.6813  5.582  1.798  1.645  4.617  6.460  5.406  0.2299  1.729  3.756   \n",
       "617   0.7810  5.420  3.244  1.383  6.707  5.930  4.285  1.7680  1.658  3.490   \n",
       "6024  0.7525  3.643  2.258  1.564  4.406  5.480  3.965  2.2320  2.465  4.540   \n",
       "2179  0.7225  4.940  3.572  2.998  5.610  6.210  3.742  2.6170  3.291  4.030   \n",
       "\n",
       "      ...  ZMYM2  ZNF131  ZNF274  ZNF318  ZNF395  ZNF451  ZNF586  ZNF589  \\\n",
       "3957  ...  2.553   2.572  2.2480   1.669   1.379   2.100  0.8564  0.9795   \n",
       "2828  ...  3.736   2.334  2.8540   1.854   2.549   2.111  0.7880  1.1180   \n",
       "617   ...  3.049   2.375  2.8460   2.201   3.309   2.190  0.7950  1.5810   \n",
       "6024  ...  2.994   1.978 -0.9106   1.951   2.781   2.055 -0.1396  2.1660   \n",
       "2179  ...  2.297   2.037  2.4800   2.887   2.504   2.270  1.2280  1.8050   \n",
       "\n",
       "       ZW10  FEATURE  \n",
       "3957  2.460      8.0  \n",
       "2828  2.793      6.0  \n",
       "617   3.123      1.0  \n",
       "6024  2.387     13.0  \n",
       "2179  1.628      4.0  \n",
       "\n",
       "[5 rows x 944 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to reload data as we changed things in cells up above, and df_R was modifed\n",
    "df_R = pd.read_csv(\"/Users/austin/combined_single_response_agg\", sep='\\t', engine='c', low_memory=False)\n",
    "\n",
    "#reduce samples to make this run faster, this time to just CCLE \n",
    "df_R = df_R[df_R.SOURCE == 'CCLE'][['CELL', 'DRUG', 'AUC']]\n",
    "\n",
    "tmp = pd.merge(left=df_R, right=df_T, on='CELL', how='inner')\n",
    "df = pd.merge(left=tmp, right=df_D, on='DRUG', how='inner')\n",
    "df = df.drop(['CELL', 'DRUG'], axis=1) # remove the columns we used for merging feature frames\n",
    "\n",
    "#encode ordinal \n",
    "oridinal_encoder = sklearn.preprocessing.OrdinalEncoder()\n",
    "df.iloc[:,-1] = oridinal_encoder.fit_transform(\n",
    "    np.array(df.iloc[:,-1]).reshape(-1, 1) #ordinal_encoder will throw an error if you don't do this\n",
    ")\n",
    "\n",
    "X, y = np.array(df.iloc[:,1:]), np.array(df.iloc[:,0], dtype=np.float32)\n",
    "\n",
    "df.sample(frac=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice now we have numerical features that seem to be scaled, plus one ordinal feature for the drug name. Also see the data is a lot bigger now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Task Model\n",
    "We will limit drugs to a single feature. This is easy as our drugs are ordinally encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>AARS</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>ABCF3</th>\n",
       "      <th>ABHD4</th>\n",
       "      <th>ABHD6</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACAA1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMIZ1</th>\n",
       "      <th>ZMYM2</th>\n",
       "      <th>ZNF131</th>\n",
       "      <th>ZNF274</th>\n",
       "      <th>ZNF318</th>\n",
       "      <th>ZNF395</th>\n",
       "      <th>ZNF451</th>\n",
       "      <th>ZNF586</th>\n",
       "      <th>ZNF589</th>\n",
       "      <th>ZW10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1116</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>6.332</td>\n",
       "      <td>3.5080</td>\n",
       "      <td>2.725</td>\n",
       "      <td>4.863</td>\n",
       "      <td>5.180</td>\n",
       "      <td>4.470</td>\n",
       "      <td>1.3760</td>\n",
       "      <td>2.475</td>\n",
       "      <td>4.395</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3440</td>\n",
       "      <td>2.617</td>\n",
       "      <td>2.504</td>\n",
       "      <td>3.068</td>\n",
       "      <td>3.180</td>\n",
       "      <td>3.645</td>\n",
       "      <td>2.258</td>\n",
       "      <td>1.6190</td>\n",
       "      <td>2.4220</td>\n",
       "      <td>2.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1331</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>8.320</td>\n",
       "      <td>1.7350</td>\n",
       "      <td>1.895</td>\n",
       "      <td>5.810</td>\n",
       "      <td>5.344</td>\n",
       "      <td>3.898</td>\n",
       "      <td>1.9230</td>\n",
       "      <td>1.567</td>\n",
       "      <td>3.393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>1.930</td>\n",
       "      <td>1.670</td>\n",
       "      <td>2.846</td>\n",
       "      <td>2.777</td>\n",
       "      <td>1.350</td>\n",
       "      <td>1.685</td>\n",
       "      <td>-0.2770</td>\n",
       "      <td>2.5210</td>\n",
       "      <td>1.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>658</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>4.805</td>\n",
       "      <td>3.2380</td>\n",
       "      <td>3.236</td>\n",
       "      <td>3.795</td>\n",
       "      <td>5.710</td>\n",
       "      <td>4.008</td>\n",
       "      <td>0.3628</td>\n",
       "      <td>1.255</td>\n",
       "      <td>2.707</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7960</td>\n",
       "      <td>1.471</td>\n",
       "      <td>1.521</td>\n",
       "      <td>4.367</td>\n",
       "      <td>2.277</td>\n",
       "      <td>1.364</td>\n",
       "      <td>1.763</td>\n",
       "      <td>1.2070</td>\n",
       "      <td>0.7563</td>\n",
       "      <td>1.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1322</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>6.890</td>\n",
       "      <td>1.5205</td>\n",
       "      <td>1.872</td>\n",
       "      <td>4.863</td>\n",
       "      <td>5.277</td>\n",
       "      <td>5.023</td>\n",
       "      <td>1.4050</td>\n",
       "      <td>2.695</td>\n",
       "      <td>3.977</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5205</td>\n",
       "      <td>2.572</td>\n",
       "      <td>1.551</td>\n",
       "      <td>2.658</td>\n",
       "      <td>1.376</td>\n",
       "      <td>3.090</td>\n",
       "      <td>2.504</td>\n",
       "      <td>0.4443</td>\n",
       "      <td>2.1660</td>\n",
       "      <td>1.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>871</td>\n",
       "      <td>0.6129</td>\n",
       "      <td>7.050</td>\n",
       "      <td>1.4720</td>\n",
       "      <td>1.292</td>\n",
       "      <td>5.883</td>\n",
       "      <td>7.074</td>\n",
       "      <td>6.190</td>\n",
       "      <td>1.1900</td>\n",
       "      <td>2.969</td>\n",
       "      <td>2.873</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8440</td>\n",
       "      <td>3.260</td>\n",
       "      <td>2.492</td>\n",
       "      <td>3.469</td>\n",
       "      <td>2.777</td>\n",
       "      <td>1.744</td>\n",
       "      <td>3.908</td>\n",
       "      <td>1.9360</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>3.123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC   AARS   ABCB6  ABCC5  ABCF1  ABCF3  ABHD4   ABHD6   ABL1  ACAA1  \\\n",
       "1116  0.0541  6.332  3.5080  2.725  4.863  5.180  4.470  1.3760  2.475  4.395   \n",
       "1331  0.5250  8.320  1.7350  1.895  5.810  5.344  3.898  1.9230  1.567  3.393   \n",
       "658   0.4576  4.805  3.2380  3.236  3.795  5.710  4.008  0.3628  1.255  2.707   \n",
       "1322  0.6572  6.890  1.5205  1.872  4.863  5.277  5.023  1.4050  2.695  3.977   \n",
       "871   0.6129  7.050  1.4720  1.292  5.883  7.074  6.190  1.1900  2.969  2.873   \n",
       "\n",
       "      ...   ZMIZ1  ZMYM2  ZNF131  ZNF274  ZNF318  ZNF395  ZNF451  ZNF586  \\\n",
       "1116  ...  1.3440  2.617   2.504   3.068   3.180   3.645   2.258  1.6190   \n",
       "1331  ...  0.6167  1.930   1.670   2.846   2.777   1.350   1.685 -0.2770   \n",
       "658   ...  1.7960  1.471   1.521   4.367   2.277   1.364   1.763  1.2070   \n",
       "1322  ...  1.5205  2.572   1.551   2.658   1.376   3.090   2.504  0.4443   \n",
       "871   ...  2.8440  3.260   2.492   3.469   2.777   1.744   3.908  1.9360   \n",
       "\n",
       "      ZNF589   ZW10  \n",
       "1116  2.4220  2.473  \n",
       "1331  2.5210  1.147  \n",
       "658   0.7563  1.403  \n",
       "1322  2.1660  1.489  \n",
       "871   0.3170  3.123  \n",
       "\n",
       "[5 rows x 943 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# We want to reload data as we changed things in cells up above, and df_R was modifed\n",
    "df_R = pd.read_csv(\"/Users/austin/combined_single_response_agg\", sep='\\t', engine='c', low_memory=False)\n",
    "\n",
    "d = ['CCLE.18', 'GDSC.11', 'CTRP.410'] #these are all actually the same drug... confusing reality of the data.\n",
    "\n",
    "#limit ourselves to a single d in D\n",
    "df_R = df_R[df_R.DRUG.isin(d)][['CELL', 'DRUG', 'AUC']]\n",
    "\n",
    "df = pd.merge(left=df_R, right=df_T, on='CELL', how='inner')\n",
    "# NOTICE: we do not merge in drug features.\n",
    "df = df.drop(['CELL', 'DRUG'], axis=1) # remove the columns we used for merging feature frames\n",
    "\n",
    "X, y = np.array(df.iloc[:,1:]), np.array(df.iloc[:,0], dtype=np.float32)\n",
    "\n",
    "df.sample(frac=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1486, 942) (1486,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 42.,  76., 183., 264., 260., 237., 160., 123.,  85.,  56.]),\n",
       " array([0.033 , 0.1297, 0.2264, 0.3231, 0.4198, 0.5165, 0.6132, 0.7099,\n",
       "        0.8066, 0.9033, 1.    ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying regression model:\n",
      "Avg regression metrics:\n",
      "+--------------------+----------------------+\n",
      "|        key         |        value         |\n",
      "+--------------------+----------------------+\n",
      "|         r2         | -0.1714116976120157  |\n",
      "|        mae         | 0.17067933966487694  |\n",
      "| mean_squared_error | 0.044235176573293324 |\n",
      "+--------------------+----------------------+\n",
      "Trying classif model:\n",
      "Avg classif Metrics\n",
      "+-----------+---------------------+\n",
      "|    key    |        value        |\n",
      "+-----------+---------------------+\n",
      "|    acc    |  0.6103111653447224 |\n",
      "|   balacc  |  0.6082784801140948 |\n",
      "|    mcc    | 0.22282677562313907 |\n",
      "| precision |  0.6397175949306477 |\n",
      "|   recall  |  0.6420382165605096 |\n",
      "|     tp    |  0.6420382165605096 |\n",
      "|     fp    | 0.42548125633232015 |\n",
      "|     tn    |  0.5745187436676799 |\n",
      "|     fn    |  0.5745187436676799 |\n",
      "+-----------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model \n",
    "\n",
    "print(\"Trying regression model:\")\n",
    "cv = sklearn.model_selection.KFold(5, random_state=42)\n",
    "avg_metrics = my_utils.DictAvg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    lr = sklearn.ensemble.RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    metrics = my_utils.get_regression_metrics(y_test, lr.predict(X_test))\n",
    "    avg_metrics(metrics)\n",
    "\n",
    "print(\"Avg regression metrics:\")\n",
    "print(my_utils.prettyPrint(avg_metrics.avg()))\n",
    "\n",
    "print(\"Trying classif model:\")\n",
    "cv = sklearn.model_selection.StratifiedKFold(5, random_state=42)\n",
    "avg_metrics = my_utils.DictAvg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "    lr = sklearn.ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    metrics = my_utils.get_bclassif_metrics(y_test, lr.predict(X_test))\n",
    "    avg_metrics(metrics)\n",
    "    \n",
    "print(\"Avg classif Metrics\")\n",
    "print(my_utils.prettyPrint(avg_metrics.avg()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg classif Metrics\n",
      "+-----------+--------------------+\n",
      "|    key    |       value        |\n",
      "+-----------+--------------------+\n",
      "|    acc    |  0.61437416672316  |\n",
      "|   balacc  | 0.6035086377687001 |\n",
      "|    mcc    | 0.2453325025127166 |\n",
      "| precision | 0.6230476368694837 |\n",
      "|   recall  | 0.7923566878980892 |\n",
      "|     tp    | 0.7923566878980892 |\n",
      "|     fp    | 0.585339412360689  |\n",
      "|     tn    | 0.414660587639311  |\n",
      "|     fn    | 0.414660587639311  |\n",
      "+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Single task deep learning model\n",
    "\n",
    "\n",
    "# We make Keras models inside of functions so that the GPU memory is deleted when the model is finished, otherwise\n",
    "# many of you would notice after a few runs, the GPU throws an out of memory error.\n",
    "def cell_thunk():\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Dense, Input\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from keras.wrappers.scikit_learn import KerasClassifier\n",
    "    def set_features(feats):\n",
    "        def make_model():\n",
    "            input_layer = Input((feats,))\n",
    "            x = Dense(16, activation='relu')(input_layer)\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "            x = Dense(1, activation='sigmoid')(x)\n",
    "            model = Model(input_layer, x)\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "            return model\n",
    "        return make_model\n",
    "\n",
    "\n",
    "    cv = sklearn.model_selection.StratifiedKFold(5, random_state=42)\n",
    "    avg_metrics = my_utils.DictAvg()\n",
    "    for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "        lr = Pipeline(memory=None, \n",
    "                        steps=[('scaling', MinMaxScaler()),\n",
    "                               ('model', KerasClassifier(set_features(X.shape[1]), epochs=10, batch_size=32, verbose=0))],\n",
    "                       )        \n",
    "        lr.fit(X_train, y_train,  model__class_weight={0 : 1.0, 1:2.0})\n",
    "        metrics = my_utils.get_bclassif_metrics(y_test, lr.predict(X_test))\n",
    "        avg_metrics(metrics)\n",
    "        \n",
    "        del lr #clean memory\n",
    "    print(\"Avg classif Metrics\")\n",
    "    print(my_utils.prettyPrint(avg_metrics.avg()))\n",
    "\n",
    "cell_thunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multitask model\n",
    "Now we will use four drugs, that we featurize just 0 to 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>AARS</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>ABCF3</th>\n",
       "      <th>ABHD4</th>\n",
       "      <th>ABHD6</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACAA1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMYM2</th>\n",
       "      <th>ZNF131</th>\n",
       "      <th>ZNF274</th>\n",
       "      <th>ZNF318</th>\n",
       "      <th>ZNF395</th>\n",
       "      <th>ZNF451</th>\n",
       "      <th>ZNF586</th>\n",
       "      <th>ZNF589</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>FEATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1243</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.834</td>\n",
       "      <td>1.940</td>\n",
       "      <td>3.871</td>\n",
       "      <td>4.780</td>\n",
       "      <td>3.240</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>1.225</td>\n",
       "      <td>2.785</td>\n",
       "      <td>...</td>\n",
       "      <td>1.627</td>\n",
       "      <td>1.4510</td>\n",
       "      <td>2.098</td>\n",
       "      <td>1.963</td>\n",
       "      <td>1.583</td>\n",
       "      <td>1.752</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1.7030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3247</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>5.273</td>\n",
       "      <td>2.660</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.727</td>\n",
       "      <td>6.130</td>\n",
       "      <td>3.890</td>\n",
       "      <td>-0.4058</td>\n",
       "      <td>1.688</td>\n",
       "      <td>3.360</td>\n",
       "      <td>...</td>\n",
       "      <td>3.406</td>\n",
       "      <td>0.4597</td>\n",
       "      <td>2.550</td>\n",
       "      <td>3.560</td>\n",
       "      <td>2.432</td>\n",
       "      <td>2.324</td>\n",
       "      <td>1.269</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4549</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>4.990</td>\n",
       "      <td>3.934</td>\n",
       "      <td>4.500</td>\n",
       "      <td>5.473</td>\n",
       "      <td>5.880</td>\n",
       "      <td>3.906</td>\n",
       "      <td>2.7360</td>\n",
       "      <td>3.390</td>\n",
       "      <td>2.156</td>\n",
       "      <td>...</td>\n",
       "      <td>4.350</td>\n",
       "      <td>3.2170</td>\n",
       "      <td>3.104</td>\n",
       "      <td>2.930</td>\n",
       "      <td>2.826</td>\n",
       "      <td>2.943</td>\n",
       "      <td>1.413</td>\n",
       "      <td>1.681</td>\n",
       "      <td>1.6600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>5.203</td>\n",
       "      <td>3.550</td>\n",
       "      <td>2.633</td>\n",
       "      <td>4.360</td>\n",
       "      <td>5.414</td>\n",
       "      <td>4.700</td>\n",
       "      <td>2.1000</td>\n",
       "      <td>2.525</td>\n",
       "      <td>4.310</td>\n",
       "      <td>...</td>\n",
       "      <td>2.893</td>\n",
       "      <td>1.9870</td>\n",
       "      <td>1.990</td>\n",
       "      <td>2.908</td>\n",
       "      <td>3.191</td>\n",
       "      <td>2.234</td>\n",
       "      <td>1.200</td>\n",
       "      <td>2.004</td>\n",
       "      <td>2.6210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2651</td>\n",
       "      <td>0.6956</td>\n",
       "      <td>6.130</td>\n",
       "      <td>3.904</td>\n",
       "      <td>1.815</td>\n",
       "      <td>5.530</td>\n",
       "      <td>5.863</td>\n",
       "      <td>4.625</td>\n",
       "      <td>1.8560</td>\n",
       "      <td>2.475</td>\n",
       "      <td>4.890</td>\n",
       "      <td>...</td>\n",
       "      <td>3.195</td>\n",
       "      <td>2.1760</td>\n",
       "      <td>2.846</td>\n",
       "      <td>1.800</td>\n",
       "      <td>2.490</td>\n",
       "      <td>2.336</td>\n",
       "      <td>0.788</td>\n",
       "      <td>1.473</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 944 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC   AARS  ABCB6  ABCC5  ABCF1  ABCF3  ABHD4   ABHD6   ABL1  ACAA1  \\\n",
       "1243  0.7184  5.000  2.834  1.940  3.871  4.780  3.240  0.8877  1.225  2.785   \n",
       "3247  0.8851  5.273  2.660  1.940  2.727  6.130  3.890 -0.4058  1.688  3.360   \n",
       "4549  0.3796  4.990  3.934  4.500  5.473  5.880  3.906  2.7360  3.390  2.156   \n",
       "465   0.4907  5.203  3.550  2.633  4.360  5.414  4.700  2.1000  2.525  4.310   \n",
       "2651  0.6956  6.130  3.904  1.815  5.530  5.863  4.625  1.8560  2.475  4.890   \n",
       "\n",
       "      ...  ZMYM2  ZNF131  ZNF274  ZNF318  ZNF395  ZNF451  ZNF586  ZNF589  \\\n",
       "1243  ...  1.627  1.4510   2.098   1.963   1.583   1.752   0.946   0.687   \n",
       "3247  ...  3.406  0.4597   2.550   3.560   2.432   2.324   1.269   1.041   \n",
       "4549  ...  4.350  3.2170   3.104   2.930   2.826   2.943   1.413   1.681   \n",
       "465   ...  2.893  1.9870   1.990   2.908   3.191   2.234   1.200   2.004   \n",
       "2651  ...  3.195  2.1760   2.846   1.800   2.490   2.336   0.788   1.473   \n",
       "\n",
       "        ZW10  FEATURE  \n",
       "1243  1.7030        1  \n",
       "3247  1.9375        3  \n",
       "4549  1.6600        0  \n",
       "465   2.6210        0  \n",
       "2651  4.0620        3  \n",
       "\n",
       "[5 rows x 944 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to reload data as we changed things in cells up above, and df_R was modifed\n",
    "df_R = pd.read_csv(\"/Users/austin/combined_single_response_agg\", sep='\\t', engine='c', low_memory=False)\n",
    "\n",
    "d = ['CCLE.18', 'GDSC.11', 'CTRP.410', \n",
    "     'CCLE.24', 'GDSC.1',  'CTRP.230',\n",
    "     'CCLE.2',  'GDSC.1013', 'CTRP.378',\n",
    "     'CCLE.5',  'GDSC.119', 'CTRP.307'] #these each row all actually the same drug... confusing reality of the data.\n",
    "\n",
    "\n",
    "\n",
    "#limit ourselves to a fe different drugs d in D\n",
    "df_R = df_R[df_R.DRUG.isin(d)][['CELL', 'DRUG', 'AUC']]\n",
    "\n",
    "\n",
    "tmp = pd.merge(left=df_R, right=df_T, on='CELL', how='inner')\n",
    "df = pd.merge(left=tmp, right=df_D, on='DRUG', how='inner')\n",
    "df = df.drop(['CELL', 'DRUG'], axis=1) # remove the columns we used for merging feature frames\n",
    "\n",
    "##encode by hand to make sure  the drug names don't mess it up\n",
    "df.iloc[:,-1] = df.iloc[:,-1].apply( lambda x : {'CCLE.18' : 0, 'GDSC.11'    : 0, 'CTRP.410' : 0, \n",
    "                 'CCLE.24' : 1, 'GDSC.1'     : 1,  'CTRP.230' : 1,\n",
    "                 'CCLE.2'  : 2,  'GDSC.1013' : 2, 'CTRP.378' : 2,\n",
    "                 'CCLE.5'  : 3,  'GDSC.119'  : 3, 'CTRP.307' : 3}[x])\n",
    "\n",
    "X, y = np.array(df.iloc[:,1:]), np.array(df.iloc[:,0], dtype=np.float32)\n",
    "\n",
    "df.sample(frac=1).head() #df.sample(frac=1) just shuffles it so you can see different FEATURE_x and FEATURE_y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6111, 943) (6111,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying regression model:\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model \n",
    "\n",
    "print(\"Trying regression model:\")\n",
    "cv = sklearn.model_selection.KFold(5, random_state=42)\n",
    "avg_metrics = my_utils.DictAvg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    lr = sklearn.ensemble.RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    metrics = my_utils.get_regression_metrics(y_test, lr.predict(X_test))\n",
    "    avg_metrics(metrics)\n",
    "\n",
    "print(\"Avg regression metrics:\")\n",
    "print(my_utils.prettyPrint(avg_metrics.avg()))\n",
    "\n",
    "print(\"Trying classif model:\")\n",
    "cv = sklearn.model_selection.StratifiedKFold(5, random_state=42)\n",
    "avg_metrics = my_utils.DictAvg()\n",
    "for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "    lr = sklearn.ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    metrics = my_utils.get_bclassif_metrics(y_test, lr.predict(X_test))\n",
    "    avg_metrics(metrics)\n",
    "    \n",
    "print(\"Avg classif Metrics\")\n",
    "print(my_utils.prettyPrint(avg_metrics.avg()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow thats good improvement. Let's score the model by compound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0.0    0.556701\n",
       "1.0    0.981735\n",
       "2.0    1.000000\n",
       "3.0    0.987288\n",
       "Name: acc, dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_by_drug = pd.DataFrame(np.stack([X_test[:,-1].flatten(), y_test.flatten(), lr.predict(X_test).flatten()])).T\n",
    "scores_by_drug['r2'] = (scores_by_drug.iloc[:,1] == scores_by_drug.iloc[:,2])\n",
    "scores_by_drug.groupby(0).mean()['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i, n in enumerate(['PACLITAXEL', 'ERLOTINIB', 'NILOTINIB', 'LAPATINIB']):\n",
    "    plt.subplot('22' + str(i + 1))\n",
    "    plt.hist(df[df.iloc[:,-1] ==i].AUC)\n",
    "    plt.title(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SO we did not really do any better on paxitaxel, we just are good at predicting for the other compounds. And we're not really even better at that, we're can just predict nothing works and be basically 100% accuracte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves\n",
    "Learning curves are a way of expressing the relationship between dataset size and success. The following scenario is helpful for thinking about the function of learning curves. \n",
    "\n",
    "You are trying to convince a board to give you funding to buy 1000 more cell line screens, and they are very expensive. Your models are currently okay, but they need to be better. You need to convince the committe that adding more data will improve the model, and quantifiy that that amount of data will help you achieve that goal. \n",
    "\n",
    "We will make a plot that shows how our model does as we increase our data size, pretending that we have less data than we do in order to make this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import balanced_accuracy_score,  make_scorer\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline(memory=None, \n",
    "                    steps=[('scaling', MinMaxScaler()),\n",
    "                           ('model', RandomForestClassifier(n_estimators=25))]\n",
    "                    )\n",
    "\n",
    "\n",
    "train_sizes, train_scores, valid_scores = sklearn.model_selection.learning_curve(pipeline, \n",
    "                                                                                 X, (y <=0.5).astype(np.int32),  \n",
    "                                                                                 train_sizes=[30, 500, 1000, 2000, 3000, 4000, 5000],\n",
    "                                                                                 cv=10, \n",
    "                                                                                 shuffle=True,\n",
    "                                                                                 verbose=0,\n",
    "                                                                                 scoring=make_scorer(balanced_accuracy_score)\n",
    "                                                                                )\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(valid_scores, axis=1)\n",
    "test_scores_std = np.std(valid_scores, axis=1)\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that adding 1000 cells would indeed seem to improve our model performance. Of course this is no gaurentee, but it is strong evidence. \n",
    "\n",
    "I recomend learning more about this topic here: https://www.ncbi.nlm.nih.gov/pubmed/12804087 or https://arxiv.org/pdf/1712.00409"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice when we have an ordinal feature encoding, we must one hot encode it. Unlike other models that accept ordinal features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-task task deep learning model\n",
    "\n",
    "# TODO: Must one hot encode. I did not do this in the notebook for you. \n",
    "\n",
    "# We make Keras models inside of functions so that the GPU memory is deleted when the model is finished, otherwise\n",
    "# many of you would notice after a few runs, the GPU throws an out of memory error.\n",
    "def cell_thunk():\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Dense, Input\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from keras.wrappers.scikit_learn import KerasClassifier\n",
    "    def set_features(feats):\n",
    "        def make_model():\n",
    "            input_layer = Input((feats,))\n",
    "            x = Dense(16, activation='relu')(input_layer)\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "            x = Dense(1, activation='sigmoid')(x)\n",
    "            model = Model(input_layer, x)\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "            return model\n",
    "        return make_model\n",
    "\n",
    "\n",
    "    cv = sklearn.model_selection.StratifiedKFold(5, random_state=42)\n",
    "    avg_metrics = my_utils.DictAvg()\n",
    "    for i, (train, test) in enumerate(cv.split(X,y <= CUTOFF)):\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], (y[train] <= CUTOFF).astype(np.int32), (y[test] <= CUTOFF).astype(np.int32)\n",
    "        \n",
    "        lr = Pipeline(memory=None, \n",
    "                        steps=[('scaling', MinMaxScaler()),\n",
    "                               ('model', KerasClassifier(set_features(X.shape[1]), epochs=10, batch_size=32, verbose=0))],\n",
    "                       )        \n",
    "        lr.fit(X_train, y_train,  model__class_weight={0 : 1.0, 1:5.0})\n",
    "        metrics = my_utils.get_bclassif_metrics(y_test, lr.predict(X_test))\n",
    "        avg_metrics(metrics)\n",
    "        \n",
    "        del lr #clean memory\n",
    "    print(\"Avg classif Metrics\")\n",
    "    print(my_utils.prettyPrint(avg_metrics.avg()))\n",
    "\n",
    "cell_thunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Totally continuous model \n",
    "This is the exciting type of model we've been building up to, where we no longer restrict the model features to be a finite predetermined set such that $\\mathcal{T}\\subseteq\\mathscr{T}=\\mid n_t\\mid$ or $\\mathcal{D}\\subseteq\\mathscr{T}=\\mid n_d\\mid$. To really understand this important step, imagine how we have been encoding drugs as simply mapping CCLE.1 -> 34 and then when the model sees 34, it knows we are discussing this discrete drug. CCLE.4->35 versus GDSC.3 -> 1 has no indication that $d(\\text{CCLE.4}, \\text{GDSC.3})>d(\\text{CCLE.1}, \\text{CCLE.4})$. If we wanted to screen a new drug, the model would not understand the new number as it has never seen any training data. \n",
    "\n",
    "\n",
    "Models that are not continuous in all the inputs are not necesarrily bad--a model used for *precision oncology* will most likely not need to be contious on drugs as medical professionals will not be wondering if a new possible lead will work for a patient, rather of the set of known working drugs which one will work best? A model used for *drug discovery* will not need to be contious on cell information as drug companies will most likely be deveolping against a panel of screens it uses in its early lead process. *It is not well studied that continuity in any variable will improve model perforance, in fact the curse of dimensionality will likely lead one to conjecture it creates less performant models; continuity, however, does certainly improve the utility of the model.* \n",
    "\n",
    "\n",
    "Now let us consider that $\\mathcal{T}\\subset\\mathbb{R}^{F_t}$ and $\\mathcal{D}\\subset\\mathbb{R}^{F_d}$\n",
    "where we can imagine using our JOIN operation\n",
    "\n",
    "$$\\hat{R}=\\hat{f}_\\theta (\\mathcal{T}, \\mathcal{D}) \\leftrightarrow \\hat{f}_\\theta (\\mathcal{X}) \\quad\\text{for} \\mathcal{X}\\in\\mathbb{R}^{F_t + F_d}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRUG</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCGG</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE.18</td>\n",
       "      <td>48.9918</td>\n",
       "      <td>38.3185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.4273</td>\n",
       "      <td>2.72997</td>\n",
       "      <td>5.45994</td>\n",
       "      <td>78.4273</td>\n",
       "      <td>1.26496</td>\n",
       "      <td>...</td>\n",
       "      <td>11.4933</td>\n",
       "      <td>102.4040</td>\n",
       "      <td>853.331</td>\n",
       "      <td>7.55160</td>\n",
       "      <td>14767</td>\n",
       "      <td>129</td>\n",
       "      <td>346</td>\n",
       "      <td>429</td>\n",
       "      <td>23.36110</td>\n",
       "      <td>13.21530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLE.14</td>\n",
       "      <td>24.9674</td>\n",
       "      <td>18.9098</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.2912</td>\n",
       "      <td>2.60670</td>\n",
       "      <td>5.14670</td>\n",
       "      <td>40.2912</td>\n",
       "      <td>1.29971</td>\n",
       "      <td>...</td>\n",
       "      <td>10.7835</td>\n",
       "      <td>82.3309</td>\n",
       "      <td>421.164</td>\n",
       "      <td>7.79933</td>\n",
       "      <td>2485</td>\n",
       "      <td>64</td>\n",
       "      <td>180</td>\n",
       "      <td>226</td>\n",
       "      <td>11.00690</td>\n",
       "      <td>6.54167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLE.13</td>\n",
       "      <td>34.5673</td>\n",
       "      <td>23.3780</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.5460</td>\n",
       "      <td>2.61744</td>\n",
       "      <td>5.15821</td>\n",
       "      <td>57.5460</td>\n",
       "      <td>1.33828</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0186</td>\n",
       "      <td>95.7646</td>\n",
       "      <td>586.279</td>\n",
       "      <td>7.23801</td>\n",
       "      <td>7049</td>\n",
       "      <td>86</td>\n",
       "      <td>246</td>\n",
       "      <td>306</td>\n",
       "      <td>12.84030</td>\n",
       "      <td>9.26389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLE.24</td>\n",
       "      <td>21.7990</td>\n",
       "      <td>16.5705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.7352</td>\n",
       "      <td>2.44674</td>\n",
       "      <td>4.89349</td>\n",
       "      <td>37.7352</td>\n",
       "      <td>1.30121</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1163</td>\n",
       "      <td>64.0168</td>\n",
       "      <td>393.169</td>\n",
       "      <td>7.56094</td>\n",
       "      <td>2396</td>\n",
       "      <td>43</td>\n",
       "      <td>142</td>\n",
       "      <td>163</td>\n",
       "      <td>8.52778</td>\n",
       "      <td>6.83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLE.5</td>\n",
       "      <td>31.6465</td>\n",
       "      <td>21.3953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.1869</td>\n",
       "      <td>2.44602</td>\n",
       "      <td>4.87551</td>\n",
       "      <td>51.1869</td>\n",
       "      <td>1.27967</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5379</td>\n",
       "      <td>90.6542</td>\n",
       "      <td>580.135</td>\n",
       "      <td>8.78992</td>\n",
       "      <td>6645</td>\n",
       "      <td>59</td>\n",
       "      <td>212</td>\n",
       "      <td>244</td>\n",
       "      <td>12.03470</td>\n",
       "      <td>8.56944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DRUG      ABC    ABCGG  nAcid  nBase  SpAbs_A  SpMax_A  SpDiam_A  \\\n",
       "0  CCLE.18  48.9918  38.3185      0      0  78.4273  2.72997   5.45994   \n",
       "1  CCLE.14  24.9674  18.9098      0      1  40.2912  2.60670   5.14670   \n",
       "2  CCLE.13  34.5673  23.3780      0      1  57.5460  2.61744   5.15821   \n",
       "3  CCLE.24  21.7990  16.5705      0      0  37.7352  2.44674   4.89349   \n",
       "4   CCLE.5  31.6465  21.3953      0      1  51.1869  2.44602   4.87551   \n",
       "\n",
       "    SpAD_A  SpMAD_A  ...    SRW10    TSRW10       MW      AMW  WPath  WPol  \\\n",
       "0  78.4273  1.26496  ...  11.4933  102.4040  853.331  7.55160  14767   129   \n",
       "1  40.2912  1.29971  ...  10.7835   82.3309  421.164  7.79933   2485    64   \n",
       "2  57.5460  1.33828  ...  11.0186   95.7646  586.279  7.23801   7049    86   \n",
       "3  37.7352  1.30121  ...  10.1163   64.0168  393.169  7.56094   2396    43   \n",
       "4  51.1869  1.27967  ...  10.5379   90.6542  580.135  8.78992   6645    59   \n",
       "\n",
       "   Zagreb1  Zagreb2  mZagreb1  mZagreb2  \n",
       "0      346      429  23.36110  13.21530  \n",
       "1      180      226  11.00690   6.54167  \n",
       "2      246      306  12.84030   9.26389  \n",
       "3      142      163   8.52778   6.83333  \n",
       "4      212      244  12.03470   8.56944  \n",
       "\n",
       "[5 rows x 1826 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_D = pd.read_csv(\"/Users/austin/data/dose_response_data/data/drug/combined_mordred_descriptors.csv\")\n",
    "df_D_names = df_D.columns.tolist()\n",
    "df_D_names[0] = 'DRUG'\n",
    "df_D.columns = df_D_names\n",
    "df_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>AARS</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>ABCF3</th>\n",
       "      <th>ABHD4</th>\n",
       "      <th>ABHD6</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACAA1</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0.9389</td>\n",
       "      <td>5.594</td>\n",
       "      <td>1.4850</td>\n",
       "      <td>1.997</td>\n",
       "      <td>3.262</td>\n",
       "      <td>4.332</td>\n",
       "      <td>4.934</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>1.899</td>\n",
       "      <td>4.020</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2846</td>\n",
       "      <td>67.8138</td>\n",
       "      <td>464.086</td>\n",
       "      <td>9.66846</td>\n",
       "      <td>3619</td>\n",
       "      <td>48</td>\n",
       "      <td>164</td>\n",
       "      <td>187</td>\n",
       "      <td>11.81250</td>\n",
       "      <td>6.97222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>0.6002</td>\n",
       "      <td>5.490</td>\n",
       "      <td>3.6270</td>\n",
       "      <td>1.008</td>\n",
       "      <td>4.207</td>\n",
       "      <td>4.562</td>\n",
       "      <td>5.617</td>\n",
       "      <td>1.3310</td>\n",
       "      <td>2.312</td>\n",
       "      <td>3.281</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0186</td>\n",
       "      <td>95.7646</td>\n",
       "      <td>586.279</td>\n",
       "      <td>7.23801</td>\n",
       "      <td>7049</td>\n",
       "      <td>86</td>\n",
       "      <td>246</td>\n",
       "      <td>306</td>\n",
       "      <td>12.84030</td>\n",
       "      <td>9.26389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>0.9281</td>\n",
       "      <td>5.957</td>\n",
       "      <td>2.9100</td>\n",
       "      <td>4.190</td>\n",
       "      <td>5.184</td>\n",
       "      <td>8.240</td>\n",
       "      <td>3.898</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>2.645</td>\n",
       "      <td>4.008</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1163</td>\n",
       "      <td>64.0168</td>\n",
       "      <td>393.169</td>\n",
       "      <td>7.56094</td>\n",
       "      <td>2396</td>\n",
       "      <td>43</td>\n",
       "      <td>142</td>\n",
       "      <td>163</td>\n",
       "      <td>8.52778</td>\n",
       "      <td>6.83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.9251</td>\n",
       "      <td>2.844</td>\n",
       "      <td>3.3500</td>\n",
       "      <td>1.599</td>\n",
       "      <td>3.352</td>\n",
       "      <td>3.914</td>\n",
       "      <td>3.373</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.872</td>\n",
       "      <td>2.531</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6171</td>\n",
       "      <td>84.2491</td>\n",
       "      <td>439.237</td>\n",
       "      <td>7.08447</td>\n",
       "      <td>3463</td>\n",
       "      <td>50</td>\n",
       "      <td>184</td>\n",
       "      <td>221</td>\n",
       "      <td>7.47222</td>\n",
       "      <td>7.08333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>0.7345</td>\n",
       "      <td>4.566</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>1.747</td>\n",
       "      <td>4.330</td>\n",
       "      <td>6.176</td>\n",
       "      <td>6.380</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>1.971</td>\n",
       "      <td>4.195</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5107</td>\n",
       "      <td>79.1959</td>\n",
       "      <td>392.176</td>\n",
       "      <td>7.84352</td>\n",
       "      <td>2281</td>\n",
       "      <td>52</td>\n",
       "      <td>164</td>\n",
       "      <td>200</td>\n",
       "      <td>8.58333</td>\n",
       "      <td>6.13889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC   AARS   ABCB6  ABCC5  ABCF1  ABCF3  ABHD4   ABHD6   ABL1  ACAA1  \\\n",
       "1452  0.9389  5.594  1.4850  1.997  3.262  4.332  4.934  0.9175  1.899  4.020   \n",
       "1895  0.6002  5.490  3.6270  1.008  4.207  4.562  5.617  1.3310  2.312  3.281   \n",
       "7632  0.9281  5.957  2.9100  4.190  5.184  8.240  3.898  0.9395  2.645  4.008   \n",
       "342   0.9251  2.844  3.3500  1.599  3.352  3.914  3.373  0.6360  0.872  2.531   \n",
       "6757  0.7345  4.566  0.7554  1.747  4.330  6.176  6.380  0.9250  1.971  4.195   \n",
       "\n",
       "      ...    SRW10   TSRW10       MW      AMW  WPath  WPol  Zagreb1  Zagreb2  \\\n",
       "1452  ...  10.2846  67.8138  464.086  9.66846   3619    48      164      187   \n",
       "1895  ...  11.0186  95.7646  586.279  7.23801   7049    86      246      306   \n",
       "7632  ...  10.1163  64.0168  393.169  7.56094   2396    43      142      163   \n",
       "342   ...  10.6171  84.2491  439.237  7.08447   3463    50      184      221   \n",
       "6757  ...  10.5107  79.1959  392.176  7.84352   2281    52      164      200   \n",
       "\n",
       "      mZagreb1  mZagreb2  \n",
       "1452  11.81250   6.97222  \n",
       "1895  12.84030   9.26389  \n",
       "7632   8.52778   6.83333  \n",
       "342    7.47222   7.08333  \n",
       "6757   8.58333   6.13889  \n",
       "\n",
       "[5 rows x 2768 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to reload data as we changed things in cells up above, and df_R was modifed\n",
    "df_R = pd.read_csv(\"/Users/austin/combined_single_response_agg\", sep='\\t', engine='c', low_memory=False)\n",
    "\n",
    "#reduce samples to make this run faster, this time to just CCLE \n",
    "df_R = df_R[df_R.SOURCE == 'CCLE'][['CELL', 'DRUG', 'AUC']]\n",
    "\n",
    "tmp = pd.merge(left=df_R, right=df_T, on='CELL', how='inner')\n",
    "df = pd.merge(left=tmp, right=df_D, on='DRUG', how='inner')\n",
    "df = df.drop(['CELL', 'DRUG'], axis=1) # remove the columns we used for merging feature frames\n",
    "\n",
    "\n",
    "X, y = np.array(df.iloc[:,1:]), np.array(df.iloc[:,0], dtype=np.float32)\n",
    "\n",
    "df.sample(frac=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10971, 2767) (10971,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[learning_curve] Training set sizes: [  30  500 1000 2000 3000 5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 out of  12 | elapsed:   14.5s remaining:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done   3 out of  12 | elapsed:   31.4s remaining:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done   5 out of  12 | elapsed:  1.0min remaining:  1.4min\n",
      "/Users/austin/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=6)]: Done   7 out of  12 | elapsed:  1.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done   9 out of  12 | elapsed:  2.1min remaining:   42.1s\n",
      "[Parallel(n_jobs=6)]: Done  12 out of  12 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import balanced_accuracy_score,  make_scorer\n",
    "\n",
    "pipeline = Pipeline(memory=None, \n",
    "                    steps=[('scaling', MinMaxScaler()),\n",
    "                           ('model', RandomForestClassifier(n_estimators=10, n_jobs=1))]\n",
    "                    )\n",
    "\n",
    "train_sizes, train_scores, valid_scores = sklearn.model_selection.learning_curve(pipeline, \n",
    "                                                                                 X, (y <=0.5).astype(np.int32),  \n",
    "                                                                                 train_sizes=[30, 500, 1000, 2000, 3000, 5000],\n",
    "                                                                                 cv=2, \n",
    "                                                                                 shuffle=True,\n",
    "                                                                                 verbose=10,\n",
    "                                                                                 n_jobs=6,\n",
    "                                                                                 scoring=make_scorer(balanced_accuracy_score)\n",
    "                                                                                )\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(valid_scores, axis=1)\n",
    "test_scores_std = np.std(valid_scores, axis=1)\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
